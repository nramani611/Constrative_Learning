{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580b0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f049ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data.batch import Batch\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c31da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26364"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = pd.read_csv('GSE200981_scRNAseq_processed.tsv', sep='\\t')\n",
    "scRNA_data.index = scRNA_data['Gene.names']\n",
    "scRNA_data = scRNA_data.drop('Gene.names', axis=1)\n",
    "len(scRNA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c03ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping string to protein names\n",
    "string_api_url = \"https://string-db.org/api\"\n",
    "output_format = \"tsv-no-header\"\n",
    "method = \"get_string_ids\"\n",
    "\n",
    "params = {\n",
    "\n",
    "    \"identifiers\" : \"\\r\".join(list(scRNA_data.index)), # your protein list\n",
    "    \"limit\": 1,\n",
    "    \"echo_query\": 1,\n",
    "    \"species\" : 9606, # species NCBI identifier \n",
    "    \"caller_identity\" : \"www.awesome_app.org\" # your app name\n",
    "\n",
    "}\n",
    "\n",
    "request_url = \"/\".join([string_api_url, output_format, method])\n",
    "\n",
    "results = requests.post(request_url, data=params)\n",
    "\n",
    "\n",
    "protein_2_string = dict()\n",
    "string_2_protein = dict()\n",
    "\n",
    "for line in results.text.strip().split(\"\\n\"):\n",
    "    l = line.split(\"\\t\")\n",
    "    protein_identifier, string_identifier = l[0], l[2]\n",
    "    protein_2_string[protein_identifier] = string_identifier\n",
    "    string_2_protein[string_identifier] = protein_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6a6999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_T0</th>\n",
       "      <th>V2_T0</th>\n",
       "      <th>V3_T0</th>\n",
       "      <th>V4_T0</th>\n",
       "      <th>V5_T0</th>\n",
       "      <th>V6_T0</th>\n",
       "      <th>V7_T0</th>\n",
       "      <th>V8_T0</th>\n",
       "      <th>V9_T0</th>\n",
       "      <th>V10_T0</th>\n",
       "      <th>...</th>\n",
       "      <th>V247_T7</th>\n",
       "      <th>V248_T7</th>\n",
       "      <th>V249_T7</th>\n",
       "      <th>V250_T7</th>\n",
       "      <th>V251_T7</th>\n",
       "      <th>V252_T7</th>\n",
       "      <th>V253_T7</th>\n",
       "      <th>V254_T7</th>\n",
       "      <th>V255_T7</th>\n",
       "      <th>V256_T7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene.names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows × 2125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1_T0  V2_T0  V3_T0  V4_T0  V5_T0  V6_T0  V7_T0  V8_T0  V9_T0  \\\n",
       "Gene.names                                                                  \n",
       "OR4F5           0      0      0      0      0      0      0      0      0   \n",
       "OR4F3           0      0      0      0      0      0      0      0      0   \n",
       "OR4F29          0      0      0      0      0      0      0      0      0   \n",
       "OR4F16          0      0      0      0      0      0      0      0      0   \n",
       "SAMD11          0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "DAZ1            0      0      0      0      0      0      0      0      0   \n",
       "DAZ3            0      0      0      0      0      0      0      0      0   \n",
       "DAZ2            0      0      0      0      0      0      0      0      0   \n",
       "CDY1B           0      0      0      0      0      0      0      0      0   \n",
       "CDY1            0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "            V10_T0  ...  V247_T7  V248_T7  V249_T7  V250_T7  V251_T7  V252_T7  \\\n",
       "Gene.names          ...                                                         \n",
       "OR4F5            0  ...        0        0        0        0        0        0   \n",
       "OR4F3            0  ...        0        0        0        0        0        0   \n",
       "OR4F29           0  ...        0        0        0        0        0        0   \n",
       "OR4F16           0  ...        0        0        0        0        0        0   \n",
       "SAMD11           0  ...        0        0        0        0        0        0   \n",
       "...            ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "DAZ1             0  ...        0        0        0        0        0        0   \n",
       "DAZ3             0  ...        0        0        0        0        0        0   \n",
       "DAZ2             0  ...        0        0        0        0        0        0   \n",
       "CDY1B            0  ...        0        0        0        0        0        0   \n",
       "CDY1             0  ...        0        0        0        0        0        0   \n",
       "\n",
       "            V253_T7  V254_T7  V255_T7  V256_T7  \n",
       "Gene.names                                      \n",
       "OR4F5             0        0        0        0  \n",
       "OR4F3             0        0        0        0  \n",
       "OR4F29            0        0        0        0  \n",
       "OR4F16            0        0        0        0  \n",
       "SAMD11            0        0        0        0  \n",
       "...             ...      ...      ...      ...  \n",
       "DAZ1              0        0        0        0  \n",
       "DAZ3              0        0        0        0  \n",
       "DAZ2              0        0        0        0  \n",
       "CDY1B             0        0        0        0  \n",
       "CDY1              0        0        0        0  \n",
       "\n",
       "[18840 rows x 2125 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = scRNA_data.loc[list(protein_2_string.keys())]\n",
    "scRNA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d09c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "188e2405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ba9ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_protein_pairs(protein_list):\n",
    "    protein_pairs = []\n",
    "    for i in range(len(protein_list)):\n",
    "        protein1 = protein_list[i]\n",
    "        for j in range(i+1, len(protein_list)):\n",
    "            protein2 = protein_list[j]\n",
    "        \n",
    "            protein_pairs.append((protein1, protein2))\n",
    "            \n",
    "    return protein_pairs\n",
    "\n",
    "class Contrastive_Dataset(Dataset):\n",
    "    def __init__(self, scRNA_data, string_2_protein, batch_size):\n",
    "        self.counter = 0\n",
    "        self.e_counter = 0\n",
    "        self.m_counter = 0\n",
    "        self.batch_size = batch_size\n",
    "        filename = '9606.protein.links.v12.0.txt'\n",
    "\n",
    "        file = open(filename, 'r')\n",
    "        lines = file.readlines()\n",
    "        lines.pop(0)\n",
    "\n",
    "        string_2_index = dict()\n",
    "        counter = 0\n",
    "        for string_id in string_2_protein:\n",
    "            string_2_index[string_id] = counter\n",
    "            counter += 1\n",
    "\n",
    "        list_network = list()\n",
    "        \n",
    "        \"\"\"self.train_node_features = list()\n",
    "        self.train_list_outputs = list()\n",
    "        \n",
    "        self.test_node_features = list()\n",
    "        self.test_list_outputs = list()\n",
    "        \n",
    "        self.val_node_features = list()\n",
    "        self.val_list_outputs = list()\"\"\"\n",
    "        \n",
    "        self.e_nodes = list()\n",
    "        self.m_nodes = list()\n",
    "\n",
    "        print('Getting network tensor...')\n",
    "        for line in tqdm(lines):\n",
    "            line = line.strip().split(' ')\n",
    "\n",
    "            if int(line[2]) >= 999:\n",
    "\n",
    "                try:\n",
    "                    id1 = string_2_index[line[0]]\n",
    "                    id2 = string_2_index[line[1]]\n",
    "                    list_network.append([id1, id2])\n",
    "                    list_network.append([id2, id1])\n",
    "\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "        print('Getting node features tensor...')\n",
    "        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\n",
    "        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\n",
    "        \n",
    "        proteins = set([string_2_protein[string_id] for string_id in string_2_index])\n",
    "        #train_proteins, test_proteins, validate_proteins = np.split(proteins, [int(len(proteins)*0.7), int(len(proteins*0.9))])\n",
    "        \n",
    "        #train_protein_pairs = get_all_protein_pairs(train_proteins)\n",
    "        #testing_protein_pairs = get_all_protein_pairs(test_proteins)\n",
    "        #validate_protein_pairs = get_all_protein_pairs(validate_proteins)\n",
    "        \n",
    "        #for \n",
    "        \n",
    "        for column in T0_column_vals:   \n",
    "            self.e_nodes.append(torch.tensor([scRNA_data.loc[protein, column] for protein in proteins], dtype=torch.float32).to(device))\n",
    "                                        \n",
    "        for column in T8_column_vals:\n",
    "            self.m_nodes.append(torch.tensor([scRNA_data.loc[protein, column] for protein in proteins], dtype=torch.float32).to(device))\n",
    "        \n",
    "        self.edge_index = torch.tensor(list_network).t().contiguous()\n",
    "        self.edge_index = self.edge_index.to(device)\n",
    "        \n",
    "        self.e_nodes = [i.view(len(i), 1) for i in self.e_nodes]\n",
    "        self.m_nodes = [i.view(len(i), 1) for i in self.m_nodes]\n",
    "        #self.len = len(self.e_nodes)\n",
    "        #print(len(self.e_nodes), len(self.m_nodes))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.e_nodes[idx], self.m_nodes[idx], self.edge_index\n",
    "        \"\"\"if self.counter == self.batch_size:\n",
    "            self.counter = 0\n",
    "        if self.counter < self.batch_size//2:\n",
    "            self.counter += 1\n",
    "            self.e_counter += 1\n",
    "            return self.e_nodes[self.e_counter - 1], self.edge_index\n",
    "        elif self.counter >= self.batch_size//2:\n",
    "            self.counter += 1\n",
    "            self.m_counter += 1\n",
    "            return self.m_nodes[self.m_counter-1], self.edge_index\"\"\"\n",
    "            \n",
    "    def get_e_nodes(self):\n",
    "        return self.e_nodes\n",
    "    \n",
    "    def get_m_nodes(self):\n",
    "        return self.m_nodes#[0:10]\n",
    "    \n",
    "    def get_edge_index(self):\n",
    "        return self.edge_index\n",
    "\n",
    "    def shuffle(self):\n",
    "        random.shuffle(self.e_nodes)\n",
    "        random.shuffle(self.m_nodes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.e_nodes), len(self.m_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41e2140c-0f5d-40a8-9b20-a6046b77d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_collate_fn(batch):\n",
    "    m_node_features = []\n",
    "    e_node_features = []\n",
    "    graph_list = []\n",
    "    counter = 0\n",
    "    batch_size = len(batch)\n",
    "    \n",
    "    for ex in batch:\n",
    "        e_node, m_node, graph = ex\n",
    "        num_nodes = e_node.shape[0]\n",
    "        m_node_features.append(m_node)\n",
    "        e_node_features.append(e_node)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        graph_list.append(graph + num_nodes*i)\n",
    "    graphs_2 = graph_list[0:2]\n",
    "\n",
    "    e_node_features = torch.stack(e_node_features, dim=0)\n",
    "    e_node_features = torch.reshape(e_node_features, (e_node_features.shape[0]*e_node_features.shape[1], e_node_features.shape[2]))\n",
    "    \n",
    "    graphs = torch.cat(graph_list, 1)\n",
    "    graphs_2 = torch.cat(graphs_2, 1)\n",
    "\n",
    "    m_node_features = torch.stack(m_node_features, dim=0)\n",
    "    m_node_features = torch.reshape(m_node_features, (m_node_features.shape[0]*m_node_features.shape[1], m_node_features.shape[2]))\n",
    "    \n",
    "    return e_node_features, m_node_features, graphs_2, graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c526903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting network tensor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13715404/13715404 [00:06<00:00, 1971411.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting node features tensor...\n",
      "383 256\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "contrastive_dataset = Contrastive_Dataset(scRNA_data, string_2_protein, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05044b87-6f3f-402e-a92b-884da9b54716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contrastive_dataloader = DataLoader(contrastive_dataset, batch_size=batch_size, shuffle=True, collate_fn=graph_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fed0a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x1, x2, temp):\n",
    "    return (torch.dot(x1.reshape(x1.shape[1]), x2.reshape(x2.shape[1]))/(torch.norm(x1)*torch.norm(x2)))/temp\n",
    "    \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temp = 0.05\n",
    "    \n",
    "    def forward(self, zn, zd):\n",
    "        zi = zn[0, :, :]\n",
    "        zj = zn[1, :, :]\n",
    "        num = cosine_similarity(zi, zj, self.temp)\n",
    "\n",
    "        denom = sum([torch.exp(cosine_similarity(zi, zd[i, :, :], self.temp)) for i in range(zd.shape[0])])\n",
    "        return torch.multiply(torch.log(torch.divide(num, denom)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ee06d8f-d772-4702-a898-0fd87a54b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, dataset, gat, mlp, optimizer):\n",
    "    torch.cuda.empty_cache()\n",
    "    criterion = ContrastiveLoss()\n",
    "    plot_losses = []\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        dataset.shuffle()\n",
    "        dataloader = DataLoader(dataset, batch_size=10, shuffle=False, collate_fn=graph_collate_fn)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        for batch in tqdm(dataloader):\n",
    "            batch_losses = []\n",
    "            e_nodes, m_nodes, graphs_2, graphs = batch\n",
    "            batch_size = e_nodes.shape[0]//18840\n",
    "            e_nodes_unstacked = torch.reshape(e_nodes, (batch_size, 1, -1))\n",
    "\n",
    "            zd = gat(m_nodes, graphs)\n",
    "            zd = mlp(zd)\n",
    "\n",
    "            all_losses = []\n",
    "            for i in range(e_nodes_unstacked.shape[0]):\n",
    "                xi = e_nodes_unstacked[i]\n",
    "                #print(xi)\n",
    "                for j in range(e_nodes_unstacked.shape[0]):\n",
    "                    if i == j: continue\n",
    "                    xj = e_nodes_unstacked[j]\n",
    "                    xn = torch.stack([xi, xj], dim=0)\n",
    "                    xn = torch.reshape(xn, (xn.shape[0]*xn.shape[2], xn.shape[1]))\n",
    "                    zn = gat(xn, graphs_2)\n",
    "                    zn = mlp(zn)\n",
    "\n",
    "                    loss = criterion(zn, zd)\n",
    "                    all_losses.append(loss)\n",
    "                    \n",
    "            final_loss = sum(all_losses)/len(all_losses)\n",
    "            plot_losses.append(final_loss.item())\n",
    "            #print(final_loss)\n",
    "            final_loss.backward()\n",
    "            optimizer.step()\n",
    "            #final_loss.detach()\n",
    "\n",
    "            m_nodes_unstacked = torch.reshape(m_nodes, (batch_size, 1, -1))\n",
    "\n",
    "            zd = gat(e_nodes, graphs)\n",
    "            zd = mlp(zd)\n",
    "\n",
    "            all_losses = []\n",
    "            for i in range(m_nodes_unstacked.shape[0]):\n",
    "                xi = m_nodes_unstacked[i]\n",
    "                #print(xi)\n",
    "                for j in range(m_nodes_unstacked.shape[0]):\n",
    "                    if i == j: continue\n",
    "                    xj = m_nodes_unstacked[j]\n",
    "                    xn = torch.stack([xi, xj], dim=0)\n",
    "                    xn = torch.reshape(xn, (xn.shape[0]*xn.shape[2], xn.shape[1]))\n",
    "                    zn = gat(xn, graphs_2)\n",
    "                    zn = mlp(zn)\n",
    "\n",
    "                    loss = criterion(zn, zd)\n",
    "                    all_losses.append(loss)\n",
    "                    \n",
    "            final_loss = sum(all_losses)/len(all_losses)\n",
    "            plot_losses.append(final_loss.item())\n",
    "            #print(final_loss)\n",
    "            final_loss.backward()\n",
    "            optimizer.step()\n",
    "            #final_loss.detach()\n",
    "        #plot_losses.append(sum(final_loss)/len(final_loss)) \n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0bad582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_Contrast(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout = 0.6)\n",
    "        #self.output_layer = nn.Linear(out_channels*heads, 2)\n",
    "        #self.conv2 = GATConv(hidden_channels*heads, out_channels, heads, dropout=0.6)\n",
    "        self.num_nodes = 18840\n",
    "        #self.columns = out_channels*heads\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        batch_size = x.shape[0]//self.num_nodes\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.linear2 = nn.Linear(hidden_channels, out_channels)\n",
    "        self.num_nodes = 18840\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]//self.num_nodes\n",
    "        x = torch.reshape(x, (batch_size, 1, -1))\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bc55b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def GAT_contrast_train(gat, mlp, dataset, epochs, num_nodes, lr = 1e-4, weight_decay = 5e-4, temp=0.05):\n",
    "    torch.cuda.empty_cache()\n",
    "    params = list(gat.parameters()) + list(mlp.parameters())\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    criterion = ContrastiveLoss()\n",
    "    gat.train()\n",
    "    mlp.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    e_nodes = dataset.get_e_nodes()\n",
    "    m_nodes = dataset.get_m_nodes()\n",
    "    edge_index = dataset.get_edge_index()\n",
    "\n",
    "    losses = train_model(epochs, dataset, gat, mlp, optimizer)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3d2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to put in tensor batches again\n",
    "gat_contrast = GAT_Contrast(1, 16, 2, 1).to(device)\n",
    "mlp_contrast = MLP(301440, 64, 32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4d855cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/39 [00:01<00:49,  1.29s/it]\u001b[A\n",
      "  5%|▌         | 2/39 [00:02<00:46,  1.24s/it]\u001b[A\n",
      "  8%|▊         | 3/39 [00:03<00:42,  1.17s/it]\u001b[A\n",
      " 10%|█         | 4/39 [00:04<00:39,  1.14s/it]\u001b[A\n",
      " 13%|█▎        | 5/39 [00:05<00:38,  1.12s/it]\u001b[A\n",
      " 15%|█▌        | 6/39 [00:06<00:36,  1.11s/it]\u001b[A\n",
      " 18%|█▊        | 7/39 [00:07<00:35,  1.11s/it]\u001b[A\n",
      " 21%|██        | 8/39 [00:09<00:34,  1.10s/it]\u001b[A\n",
      " 23%|██▎       | 9/39 [00:10<00:32,  1.10s/it]\u001b[A\n",
      " 26%|██▌       | 10/39 [00:11<00:32,  1.14s/it]\u001b[A\n",
      " 28%|██▊       | 11/39 [00:12<00:31,  1.12s/it]\u001b[A\n",
      " 31%|███       | 12/39 [00:13<00:30,  1.11s/it]\u001b[A\n",
      " 33%|███▎      | 13/39 [00:14<00:28,  1.11s/it]\u001b[A\n",
      " 36%|███▌      | 14/39 [00:15<00:27,  1.10s/it]\u001b[A\n",
      " 38%|███▊      | 15/39 [00:16<00:26,  1.10s/it]\u001b[A\n",
      " 41%|████      | 16/39 [00:17<00:25,  1.10s/it]\u001b[A\n",
      " 44%|████▎     | 17/39 [00:18<00:24,  1.10s/it]\u001b[A\n",
      " 46%|████▌     | 18/39 [00:20<00:22,  1.09s/it]\u001b[A\n",
      " 49%|████▊     | 19/39 [00:21<00:21,  1.09s/it]\u001b[A\n",
      " 51%|█████▏    | 20/39 [00:22<00:21,  1.13s/it]\u001b[A\n",
      " 54%|█████▍    | 21/39 [00:23<00:20,  1.12s/it]\u001b[A\n",
      " 56%|█████▋    | 22/39 [00:24<00:18,  1.11s/it]\u001b[A\n",
      " 59%|█████▉    | 23/39 [00:25<00:17,  1.11s/it]\u001b[A\n",
      " 62%|██████▏   | 24/39 [00:26<00:16,  1.10s/it]\u001b[A\n",
      " 64%|██████▍   | 25/39 [00:27<00:15,  1.11s/it]\u001b[A\n",
      "  0%|          | 0/500 [00:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mGAT_contrast_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgat_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrastive_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscRNA_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m, in \u001b[0;36mGAT_contrast_train\u001b[0;34m(gat, mlp, dataset, epochs, num_nodes, lr, weight_decay, temp)\u001b[0m\n\u001b[1;32m     14\u001b[0m m_nodes \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_m_nodes()\n\u001b[1;32m     15\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_edge_index()\n\u001b[0;32m---> 17\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m losses\n",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epochs, dataset, gat, mlp, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mgraph_collate_fn)\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     11\u001b[0m     batch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m     e_nodes, m_nodes, graphs_2, graphs \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/venvs/contlearn/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/contlearn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/venvs/contlearn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/venvs/contlearn/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/venvs/contlearn/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[8], line 86\u001b[0m, in \u001b[0;36mContrastive_Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me_nodes[idx], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm_nodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"if self.counter == self.batch_size:\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m        self.counter = 0\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    if self.counter < self.batch_size//2:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m        self.m_counter += 1\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m        return self.m_nodes[self.m_counter-1], self.edge_index\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "losses = GAT_contrast_train(gat_contrast, mlp_contrast, contrastive_dataset, 500, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44be1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1bc60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
