{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4cd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nramani/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429182e7",
   "metadata": {},
   "source": [
    "# Useful Links\n",
    "Implementing data object for neural networks:\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "\n",
    "Writing a custom dataset class: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Writing a GAT Class example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py\n",
    "\n",
    "Dataloaders for Batch Training: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "Splitting datasets for training and testing: https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split\n",
    "\n",
    "Batching with GNNs: https://github.com/pyg-team/pytorch_geometric/issues/973, https://github.com/gordicaleksa/pytorch-GAT/blob/main/The%20Annotated%20GAT%20(PPI).ipynb\n",
    "\n",
    "Global Mean Pool: https://github.com/pyg-team/pytorch_geometric/discussions/3516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb818778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26364"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = pd.read_csv('GSE200981_scRNAseq_processed.tsv', sep='\\t')\n",
    "scRNA_data.index = scRNA_data['Gene.names']\n",
    "scRNA_data = scRNA_data.drop('Gene.names', axis=1)\n",
    "len(scRNA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d591b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping string to protein names\n",
    "string_api_url = \"https://string-db.org/api\"\n",
    "output_format = \"tsv-no-header\"\n",
    "method = \"get_string_ids\"\n",
    "\n",
    "params = {\n",
    "\n",
    "    \"identifiers\" : \"\\r\".join(list(scRNA_data.index)), # your protein list\n",
    "    \"limit\": 1,\n",
    "    \"echo_query\": 1,\n",
    "    \"species\" : 9606, # species NCBI identifier \n",
    "    \"caller_identity\" : \"www.awesome_app.org\" # your app name\n",
    "\n",
    "}\n",
    "\n",
    "request_url = \"/\".join([string_api_url, output_format, method])\n",
    "\n",
    "results = requests.post(request_url, data=params)\n",
    "\n",
    "\n",
    "protein_2_string = dict()\n",
    "string_2_protein = dict()\n",
    "\n",
    "for line in results.text.strip().split(\"\\n\"):\n",
    "    l = line.split(\"\\t\")\n",
    "    protein_identifier, string_identifier = l[0], l[2]\n",
    "    protein_2_string[protein_identifier] = string_identifier\n",
    "    string_2_protein[string_identifier] = protein_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acda1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_T0</th>\n",
       "      <th>V2_T0</th>\n",
       "      <th>V3_T0</th>\n",
       "      <th>V4_T0</th>\n",
       "      <th>V5_T0</th>\n",
       "      <th>V6_T0</th>\n",
       "      <th>V7_T0</th>\n",
       "      <th>V8_T0</th>\n",
       "      <th>V9_T0</th>\n",
       "      <th>V10_T0</th>\n",
       "      <th>...</th>\n",
       "      <th>V247_T7</th>\n",
       "      <th>V248_T7</th>\n",
       "      <th>V249_T7</th>\n",
       "      <th>V250_T7</th>\n",
       "      <th>V251_T7</th>\n",
       "      <th>V252_T7</th>\n",
       "      <th>V253_T7</th>\n",
       "      <th>V254_T7</th>\n",
       "      <th>V255_T7</th>\n",
       "      <th>V256_T7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene.names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows × 2125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1_T0  V2_T0  V3_T0  V4_T0  V5_T0  V6_T0  V7_T0  V8_T0  V9_T0  \\\n",
       "Gene.names                                                                  \n",
       "OR4F5           0      0      0      0      0      0      0      0      0   \n",
       "OR4F3           0      0      0      0      0      0      0      0      0   \n",
       "OR4F29          0      0      0      0      0      0      0      0      0   \n",
       "OR4F16          0      0      0      0      0      0      0      0      0   \n",
       "SAMD11          0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "DAZ1            0      0      0      0      0      0      0      0      0   \n",
       "DAZ3            0      0      0      0      0      0      0      0      0   \n",
       "DAZ2            0      0      0      0      0      0      0      0      0   \n",
       "CDY1B           0      0      0      0      0      0      0      0      0   \n",
       "CDY1            0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "            V10_T0  ...  V247_T7  V248_T7  V249_T7  V250_T7  V251_T7  V252_T7  \\\n",
       "Gene.names          ...                                                         \n",
       "OR4F5            0  ...        0        0        0        0        0        0   \n",
       "OR4F3            0  ...        0        0        0        0        0        0   \n",
       "OR4F29           0  ...        0        0        0        0        0        0   \n",
       "OR4F16           0  ...        0        0        0        0        0        0   \n",
       "SAMD11           0  ...        0        0        0        0        0        0   \n",
       "...            ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "DAZ1             0  ...        0        0        0        0        0        0   \n",
       "DAZ3             0  ...        0        0        0        0        0        0   \n",
       "DAZ2             0  ...        0        0        0        0        0        0   \n",
       "CDY1B            0  ...        0        0        0        0        0        0   \n",
       "CDY1             0  ...        0        0        0        0        0        0   \n",
       "\n",
       "            V253_T7  V254_T7  V255_T7  V256_T7  \n",
       "Gene.names                                      \n",
       "OR4F5             0        0        0        0  \n",
       "OR4F3             0        0        0        0  \n",
       "OR4F29            0        0        0        0  \n",
       "OR4F16            0        0        0        0  \n",
       "SAMD11            0        0        0        0  \n",
       "...             ...      ...      ...      ...  \n",
       "DAZ1              0        0        0        0  \n",
       "DAZ3              0        0        0        0  \n",
       "DAZ2              0        0        0        0  \n",
       "CDY1B             0        0        0        0  \n",
       "CDY1              0        0        0        0  \n",
       "\n",
       "[18840 rows x 2125 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = scRNA_data.loc[list(protein_2_string.keys())]\n",
    "scRNA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284f7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nramani/.local/lib/python3.10/site-packages/torch_geometric/utils/convert.py:4: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.3)\n",
      "  import scipy.sparse\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data.batch import Batch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3573dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be15c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting network tensor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 13715404/13715404 [00:05<00:00, 2456322.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting node features tensor...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from dataset import EMT_Dataset\n",
    "dataset = EMT_Dataset(scRNA_data, string_2_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99eddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "train_length = int(0.7*len(dataset))\n",
    "training_dataset, testing_dataset = random_split(dataset, [train_length, len(dataset)-train_length], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000de176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_collate_fn(batch):\n",
    "    node_features_list = []\n",
    "    graph_list = []\n",
    "    outputs_list = []\n",
    "    counter = 0\n",
    "    \n",
    "    for ex in batch:\n",
    "        node_feature, graph, output = ex\n",
    "        num_nodes = node_feature.shape[0]\n",
    "        node_features_list.append(node_feature)\n",
    "        graph_list.append(graph + num_nodes*counter)\n",
    "        outputs_list.append(output)\n",
    "        counter += 1\n",
    "    \n",
    "    node_features = torch.stack(node_features_list, dim=0)\n",
    "    node_features = torch.reshape(node_features, (node_features.shape[0]*node_features.shape[1], node_features.shape[2]))\n",
    "    graphs = torch.cat(graph_list, 1)\n",
    "    outputs = torch.stack(outputs_list, dim=0)\n",
    "    \n",
    "    return node_features, graphs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83ea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=3, shuffle=True, collate_fn = graph_collate_fn)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size=3, shuffle=True, collate_fn = graph_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae02b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_batch(batch_num, num_nodes):\n",
    "    tensor_batch = torch.tensor([i for i in range(batch_num) for _ in range(num_nodes)]).to(device)\n",
    "    return tensor_batch\n",
    "\n",
    "def GAT_train(model, dataloader, epochs, num_nodes, lr = 1e-3, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    prev_batch_num = None\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            batch_num = batch[0].shape[0] // num_nodes\n",
    "            \n",
    "            if prev_batch_num != batch_num:\n",
    "                prev_batch_num = batch_num\n",
    "                tensor_batch = get_tensor_batch(prev_batch_num, num_nodes)\n",
    "            \n",
    "            node_features, graphs, outputs = batch \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            graphs = graphs.to(device)\n",
    "            node_features = node_features.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            out = model(node_features, graphs, tensor_batch)\n",
    "            print(out)\n",
    "            loss = criterion(out, outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "          \n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "        \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('GATConv E/M classification Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45188f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from GAT import GAT\n",
    "model = GAT(1, 16, dataset.num_classes(), 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "716da8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56520, 8])\n",
      "torch.Size([3, 18840, 8])\n",
      "torch.Size([3, 18840])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [56520] to be smaller than self [3] apart from dimension 0 and to be smaller size than src [3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11320/825178345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGAT_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscRNA_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11320/3051968174.py\u001b[0m in \u001b[0;36mGAT_train\u001b[0;34m(model, dataloader, epochs, num_nodes, lr, weight_decay)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mnode_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BU/Crovella/Stefan_Mark/Constrative_Learning/GAT.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, tensor_batch)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#x = torch.flatten(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print(x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/pool/glob.py\u001b[0m in \u001b[0;36mglobal_mean_pool\u001b[0;34m(x, batch, size)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/utils/_scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected index [56520] to be smaller than self [3] apart from dimension 0 and to be smaller size than src [3]"
     ]
    }
   ],
   "source": [
    "GAT_train(model, training_dataloader, 500, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAT_test(model, dataloader, num_nodes):\n",
    "    test_losses = []\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    prev_batch_num = None\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        \n",
    "        batch_num = batch[0].shape[0] // num_nodes\n",
    "            \n",
    "        if prev_batch_num != batch_num:\n",
    "            prev_batch_num = batch_num\n",
    "            tensor_batch = get_tensor_batch(prev_batch_num, num_nodes)\n",
    "        \n",
    "        node_features, graphs, outputs = batch\n",
    "        \n",
    "        graphs = graphs.to(device)\n",
    "        node_features = node_features.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        \n",
    "        out = model(node_features, graphs, tensor_batch)\n",
    "            \n",
    "        loss = criterion(out, outputs)\n",
    "        \n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "    return sum(test_losses)/len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10337b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAT_test(model, testing_dataloader, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.linear2 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cc72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "#testing_dataloader = DataLoader(testing_dataset, batch_size=32, shuffle=True)\n",
    "#mlp = MLP(dataset.num_nodes(), 16, dataset.num_classes()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46474081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_train(model, dataloader, epochs, lr = 1e-8, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        model = model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            node_features, _, outputs = batch\n",
    "            node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            out = model(node_features)\n",
    "            loss = criterion(out, outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "            \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('MLP E/M classification Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d5d8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MLP_train(mlp, training_dataloader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_test(model, dataloader):\n",
    "    test_losses = []\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        node_features, _, outputs = batch\n",
    "        node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        out = model(node_features)\n",
    "        loss = criterion(out, outputs)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "    return sum(test_losses)/len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP_test(mlp, testing_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421e107",
   "metadata": {},
   "source": [
    "# Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_all_protein_pairs(protein_list):\n",
    "    protein_pairs = []\n",
    "    for i in range(len(protein_list)):\n",
    "        protein1 = protein_list[i]\n",
    "        for j in range(i+1, len(protein_list)):\n",
    "            protein2 = protein_list[j]\n",
    "        \n",
    "            protein_pairs.append((protein1, protein2))\n",
    "            \n",
    "    return protein_pairs\n",
    "\n",
    "class Contrastive_Dataset(Dataset):\n",
    "    def __init__(self, scRNA_data, string_2_protein):\n",
    "        filename = '9606.protein.links.v12.0.txt'\n",
    "\n",
    "        file = open(filename, 'r')\n",
    "        lines = file.readlines()\n",
    "        lines.pop(0)\n",
    "\n",
    "        string_2_index = dict()\n",
    "        counter = 0\n",
    "        for string_id in string_2_protein:\n",
    "            string_2_index[string_id] = counter\n",
    "            counter += 1\n",
    "\n",
    "        list_network = list()\n",
    "        \n",
    "        \"\"\"self.train_node_features = list()\n",
    "        self.train_list_outputs = list()\n",
    "        \n",
    "        self.test_node_features = list()\n",
    "        self.test_list_outputs = list()\n",
    "        \n",
    "        self.val_node_features = list()\n",
    "        self.val_list_outputs = list()\"\"\"\n",
    "        \n",
    "        self.e_nodes = list()\n",
    "        self.m_nodes = list()\n",
    "\n",
    "        print('Getting network tensor...')\n",
    "        for line in tqdm(lines):\n",
    "            line = line.strip().split(' ')\n",
    "\n",
    "            if int(line[2]) >= 999:\n",
    "\n",
    "                try:\n",
    "                    id1 = string_2_index[line[0]]\n",
    "                    id2 = string_2_index[line[1]]\n",
    "                    list_network.append([id1, id2])\n",
    "                    list_network.append([id2, id1])\n",
    "\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "        print('Getting node features tensor...')\n",
    "        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\n",
    "        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\n",
    "        \n",
    "        proteins = set([string_2_protein[string_id] for string_id in string_2_index])\n",
    "        #train_proteins, test_proteins, validate_proteins = np.split(proteins, [int(len(proteins)*0.7), int(len(proteins*0.9))])\n",
    "        \n",
    "        #train_protein_pairs = get_all_protein_pairs(train_proteins)\n",
    "        #testing_protein_pairs = get_all_protein_pairs(test_proteins)\n",
    "        #validate_protein_pairs = get_all_protein_pairs(validate_proteins)\n",
    "        \n",
    "        #for \n",
    "        \n",
    "        for column in T0_column_vals:   \n",
    "            self.e_nodes.append(torch.tensor([scRNA_data.loc[protein, column] for protein in proteins], dtype=torch.float32).to(device))\n",
    "                                        \n",
    "        for column in T8_column_vals:\n",
    "            self.m_nodes.append(torch.tensor([scRNA_data.loc[protein, column] for protein in proteins], dtype=torch.float32).to(device))\n",
    "        \n",
    "        self.edge_index = torch.tensor(list_network).t().contiguous()\n",
    "        self.edge_index = self.edge_index.to(device)\n",
    "        #print(self.e_nodes[0].view(len(self.e_nodes[0]), 1))\n",
    "        self.e_nodes = [i.view(len(i), 1) for i in self.e_nodes]\n",
    "        self.m_nodes = [i.view(len(i), 1) for i in self.m_nodes]\n",
    "        #self.node_features = torch.tensor(self.node_features, dtype=torch.float)\n",
    "        #self.list_outputs = torch.tensor(self.list_outputs, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.edge_index\n",
    "        node_feature = torch.transpose(self.node_features[idx], 0, 1).t()\n",
    "        output = self.list_outputs[idx]\n",
    "\n",
    "        #self.idx += 1                                                                                                                                                                  \n",
    "        #if self.idx == len(self.node_features):                                                                                                                                        \n",
    "            #self.idx = 0                                                                                                                                                               \n",
    "\n",
    "        return node_feature, graph, output\n",
    "    \n",
    "    def get_e_nodes(self):\n",
    "        return self.e_nodes\n",
    "    \n",
    "    def get_m_nodes(self):\n",
    "        return self.m_nodes\n",
    "    \n",
    "    def get_edge_index(self):\n",
    "        return self.edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.node_features)\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return self.node_features[0].shape[0]\n",
    "\n",
    "    def num_classes(self):\n",
    "        return self.list_outputs[0].shape[0]\n",
    "\n",
    "    def num_features(self):\n",
    "        return self.node_features[0].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a6764",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_dataset = Contrastive_Dataset(scRNA_data, string_2_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2274b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temp = 0.05\n",
    "        self.cos = nn.CosineSimilarity(dim=0)\n",
    "        \n",
    "    def forward(self, xi, xj, xneg, edge_index, model):\n",
    "        num = torch.exp(self.cos(xi, xj)/self.temp)\n",
    "        \n",
    "        denom = torch.zeros(1, requires_grad=True).to(device)\n",
    "        for i in range(len(xneg)):\n",
    "            #print('Hello')\n",
    "            neg_val = model(xneg[i], edge_index)\n",
    "            val = torch.exp(self.cos(xi, neg_val)/self.temp)\n",
    "            denom = torch.add(denom, val)\n",
    "            neg_val = neg_val.to('cpu')\n",
    "        \n",
    "        return torch.multiply(torch.log(torch.divide(num, denom)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_dataloader = DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "#testing_dataloader = DataLoader(testing_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a241a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_Contrast(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout = 0.6)\n",
    "        self.output_layer = nn.Linear(out_channels*heads, 2)\n",
    "        self.conv2 = GATConv(hidden_channels*heads, out_channels, heads, dropout=0.6)\n",
    "        self.num_nodes = 18840\n",
    "        self.columns = out_channels*heads\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        batch_size = x.shape[0]//self.num_nodes\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = torch.reshape(x, (batch_size, self.num_nodes, self.columns))\n",
    "        x = torch.mean(x, dim=2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class GAT_Contrast(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads, dropout = 0.6)\n",
    "        self.output_layer1 = nn.Linear(hidden_channels*heads, 64)\n",
    "        self.output_layer2 = nn.Linear(64, 32)\n",
    "        self.output_layer3 = nn.Linear(32, 1)\n",
    "        #self.gat2 = GATConv(in_channels, hidden_channels, heads, dropout = 0.6)\n",
    "\n",
    "    def forward(self, x1, edge_index1):\n",
    "        #print(torch.equal(x1, x2))\n",
    "        x1 = self.gat1(x1, edge_index1)\n",
    "        x1 = F.relu(x1)\n",
    "        #print(x1)\n",
    "        #x2 = self.gat1(x2, edge_index2)\n",
    "        #x2 = F.relu(x2)\n",
    "        #print(x1, x2)\n",
    "        x1 = self.output_layer1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        #x2 = self.output_layer1(x2)\n",
    "        #x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.output_layer2(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        #x2 = self.output_layer2(x2)\n",
    "        #x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.output_layer3(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        #x2 = self.output_layer3(x2)\n",
    "        #x2 = F.relu(x2)\n",
    "        \n",
    "        #Non cosine\n",
    "        #x = torch.cat((x1, x2), 1)\n",
    "        #print(x.shape)\n",
    "        #x = self.output_layer4(x)\n",
    "        #x = torch.mean(x, dim=0)\n",
    "        #print(x)\n",
    "        #x = x.view(1, 2)\n",
    "        \n",
    "        #Cosine\n",
    "        #x = self.cos(x1, x2)\n",
    "        #print(x.item())\n",
    "        #x = torch.tensor([x.item(), 0], requires_grad=True).to(device)\n",
    "        #x = x.view(1, 2)\n",
    "        return x1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236fd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e2f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def GAT_contrast_train(model, dataset, epochs, num_nodes, lr = 1e-6, weight_decay = 5e-4, temp=0.05):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    #criterion = nn.NLLLoss().to(device)\n",
    "    criterion = ContrastiveLoss()\n",
    "    log_softmax = nn.LogSoftmax(dim=1)\n",
    "    #criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    e_nodes = dataset.get_e_nodes()\n",
    "    m_nodes = dataset.get_m_nodes()\n",
    "    edge_index = dataset.get_edge_index()\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        losses = []\n",
    "        \n",
    "        print('Training on E cells...')\n",
    "        for i in range(len(e_nodes)):\n",
    "            tensori = e_nodes[i]\n",
    "            #print(xi.shape)\n",
    "            \n",
    "            for j in range(len(e_nodes)):\n",
    "                tensorj = e_nodes[j]\n",
    "                \n",
    "                if i == j:\n",
    "                    continue\n",
    "            \n",
    "                xi = model(tensori, edge_index)\n",
    "                xj = model(tensorj, edge_index)\n",
    "                \n",
    "                loss = criterion(xi, xj, m_nodes, edge_index, model)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #print(loss.item())\n",
    "                losses.append(loss.item())\n",
    "                \n",
    "            all_losses.append(sum(losses)/len(losses))\n",
    "            print(all_losses)\n",
    "        \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('GATConv Contrastive Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aba599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu'\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_contrast = GAT_Contrast(1, 16, dataset.num_nodes(), 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f17737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GAT_contrast_train(gat_contrast, contrastive_dataset, 1, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAT_contrast_test(model, dataloader):\n",
    "    torch.cuda.empty_cache()\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    losses = []\n",
    "    \n",
    "        \n",
    "    for batch in dataloader:\n",
    "        try:\n",
    "            x1, edge_index1 = batch[0][0].to(device), batch[1][0].to(device)\n",
    "            x2, edge_index2 = batch[0][1].to(device), batch[1][1].to(device)\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        if torch.equal(batch[2][0], batch[2][1]):\n",
    "            outputs = torch.tensor([1.0]).to(device)\n",
    "        else:\n",
    "            outputs = torch.tensor([0.0]).to(device)\n",
    "    \n",
    "        out = model(x1, edge_index1, x2, edge_index2)\n",
    "        loss = criterion(out, outputs)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(sum(losses)/len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAT_contrast_test(gat_contrast, testing_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b354dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Contrast(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_channels, hidden_channels)\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_channels, 128)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "        self.linear4 = nn.Linear(64, 1)\n",
    "        #self.linear5 = nn.Linear(64*18840, 2)\n",
    "        self.cos = nn.CosineSimilarity(dim=0)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.linear1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear1(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.linear2(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear2(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.linear3(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear3(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.linear4(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear4(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        #print(x1,x2)\n",
    "        x = self.cos(x1, x2)\n",
    "        #print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_contrast = MLP_Contrast(1, 16, dataset.num_nodes()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_contrast_train(model, dataloader, epochs, lr = 1e-6, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        model = model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            node_features, _, outputs = batch\n",
    "            #print(node_features.shape)\n",
    "            try:\n",
    "                x1, x2 = node_features\n",
    "            except:\n",
    "                continue\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            \n",
    "            if torch.equal(batch[2][0], batch[2][1]):\n",
    "                outputs = torch.tensor([1.0]).to(device)\n",
    "            else:\n",
    "                outputs = torch.tensor([0.0]).to(device)\n",
    "                \n",
    "            #node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            out = model(x1, x2)\n",
    "            loss = criterion(out, outputs)\n",
    "            #print(out, outputs)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "        #print(all_losses[-1])\n",
    "            \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('MLP E/M classification Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f33b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_contrast_train(mlp_contrast, training_dataloader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_contrast_test(model, dataloader):\n",
    "    test_losses = []\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        node_features, _, outputs = batch\n",
    "        #node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "        try:\n",
    "            x1, x2 = node_features\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        \n",
    "        if torch.equal(batch[2][0], batch[2][1]):\n",
    "            outputs = torch.tensor([1.0]).to(device)\n",
    "        else:\n",
    "            outputs = torch.tensor([0.0]).to(device)\n",
    "        \n",
    "        outputs = outputs.to(device)\n",
    "        out = model(x1, x2)\n",
    "        loss = criterion(out, outputs)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "    return sum(test_losses)/len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a97886",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_contrast_test(mlp_contrast, testing_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c0cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([1, 0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e30437",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cf439",
   "metadata": {},
   "outputs": [],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42b0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
