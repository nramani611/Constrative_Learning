{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4cd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nramani/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429182e7",
   "metadata": {},
   "source": [
    "# Useful Links\n",
    "Implementing data object for neural networks:\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "\n",
    "Writing a custom dataset class: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Writing a GAT Class example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py\n",
    "\n",
    "Dataloaders for Batch Training: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "Splitting datasets for training and testing: https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split\n",
    "\n",
    "Batching with GNNs: https://github.com/pyg-team/pytorch_geometric/issues/973, https://github.com/gordicaleksa/pytorch-GAT/blob/main/The%20Annotated%20GAT%20(PPI).ipynb\n",
    "\n",
    "Global Mean Pool: https://github.com/pyg-team/pytorch_geometric/discussions/3516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb818778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26364"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = pd.read_csv('GSE200981_scRNAseq_processed.tsv', sep='\\t')\n",
    "scRNA_data.index = scRNA_data['Gene.names']\n",
    "scRNA_data = scRNA_data.drop('Gene.names', axis=1)\n",
    "len(scRNA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d591b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping string to protein names\n",
    "string_api_url = \"https://string-db.org/api\"\n",
    "output_format = \"tsv-no-header\"\n",
    "method = \"get_string_ids\"\n",
    "\n",
    "params = {\n",
    "\n",
    "    \"identifiers\" : \"\\r\".join(list(scRNA_data.index)), # your protein list\n",
    "    \"limit\": 1,\n",
    "    \"echo_query\": 1,\n",
    "    \"species\" : 9606, # species NCBI identifier \n",
    "    \"caller_identity\" : \"www.awesome_app.org\" # your app name\n",
    "\n",
    "}\n",
    "\n",
    "request_url = \"/\".join([string_api_url, output_format, method])\n",
    "\n",
    "results = requests.post(request_url, data=params)\n",
    "\n",
    "\n",
    "protein_2_string = dict()\n",
    "string_2_protein = dict()\n",
    "\n",
    "for line in results.text.strip().split(\"\\n\"):\n",
    "    l = line.split(\"\\t\")\n",
    "    protein_identifier, string_identifier = l[0], l[2]\n",
    "    protein_2_string[protein_identifier] = string_identifier\n",
    "    string_2_protein[string_identifier] = protein_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acda1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_T0</th>\n",
       "      <th>V2_T0</th>\n",
       "      <th>V3_T0</th>\n",
       "      <th>V4_T0</th>\n",
       "      <th>V5_T0</th>\n",
       "      <th>V6_T0</th>\n",
       "      <th>V7_T0</th>\n",
       "      <th>V8_T0</th>\n",
       "      <th>V9_T0</th>\n",
       "      <th>V10_T0</th>\n",
       "      <th>...</th>\n",
       "      <th>V247_T7</th>\n",
       "      <th>V248_T7</th>\n",
       "      <th>V249_T7</th>\n",
       "      <th>V250_T7</th>\n",
       "      <th>V251_T7</th>\n",
       "      <th>V252_T7</th>\n",
       "      <th>V253_T7</th>\n",
       "      <th>V254_T7</th>\n",
       "      <th>V255_T7</th>\n",
       "      <th>V256_T7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene.names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows × 2125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1_T0  V2_T0  V3_T0  V4_T0  V5_T0  V6_T0  V7_T0  V8_T0  V9_T0  \\\n",
       "Gene.names                                                                  \n",
       "OR4F5           0      0      0      0      0      0      0      0      0   \n",
       "OR4F3           0      0      0      0      0      0      0      0      0   \n",
       "OR4F29          0      0      0      0      0      0      0      0      0   \n",
       "OR4F16          0      0      0      0      0      0      0      0      0   \n",
       "SAMD11          0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "DAZ1            0      0      0      0      0      0      0      0      0   \n",
       "DAZ3            0      0      0      0      0      0      0      0      0   \n",
       "DAZ2            0      0      0      0      0      0      0      0      0   \n",
       "CDY1B           0      0      0      0      0      0      0      0      0   \n",
       "CDY1            0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "            V10_T0  ...  V247_T7  V248_T7  V249_T7  V250_T7  V251_T7  V252_T7  \\\n",
       "Gene.names          ...                                                         \n",
       "OR4F5            0  ...        0        0        0        0        0        0   \n",
       "OR4F3            0  ...        0        0        0        0        0        0   \n",
       "OR4F29           0  ...        0        0        0        0        0        0   \n",
       "OR4F16           0  ...        0        0        0        0        0        0   \n",
       "SAMD11           0  ...        0        0        0        0        0        0   \n",
       "...            ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "DAZ1             0  ...        0        0        0        0        0        0   \n",
       "DAZ3             0  ...        0        0        0        0        0        0   \n",
       "DAZ2             0  ...        0        0        0        0        0        0   \n",
       "CDY1B            0  ...        0        0        0        0        0        0   \n",
       "CDY1             0  ...        0        0        0        0        0        0   \n",
       "\n",
       "            V253_T7  V254_T7  V255_T7  V256_T7  \n",
       "Gene.names                                      \n",
       "OR4F5             0        0        0        0  \n",
       "OR4F3             0        0        0        0  \n",
       "OR4F29            0        0        0        0  \n",
       "OR4F16            0        0        0        0  \n",
       "SAMD11            0        0        0        0  \n",
       "...             ...      ...      ...      ...  \n",
       "DAZ1              0        0        0        0  \n",
       "DAZ3              0        0        0        0  \n",
       "DAZ2              0        0        0        0  \n",
       "CDY1B             0        0        0        0  \n",
       "CDY1              0        0        0        0  \n",
       "\n",
       "[18840 rows x 2125 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = scRNA_data.loc[list(protein_2_string.keys())]\n",
    "scRNA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "284f7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nramani/.local/lib/python3.10/site-packages/torch_geometric/utils/convert.py:4: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.23.3)\n",
      "  import scipy.sparse\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data.batch import Batch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3573dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be15c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting network tensor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 13715404/13715404 [00:05<00:00, 2347241.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting node features tensor...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "from dataset import EMT_Dataset\n",
    "dataset = EMT_Dataset(scRNA_data, string_2_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e99eddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(42)\n",
    "train_length = int(0.7*len(dataset))\n",
    "training_dataset, testing_dataset = random_split(dataset, [train_length, len(dataset)-train_length], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "000de176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_collate_fn(batch):\n",
    "    node_features_list = []\n",
    "    graph_list = []\n",
    "    outputs_list = []\n",
    "    counter = 0\n",
    "    \n",
    "    for ex in batch:\n",
    "        node_feature, graph, output = ex\n",
    "        num_nodes = node_feature.shape[0]\n",
    "        node_features_list.append(node_feature)\n",
    "        graph_list.append(graph + num_nodes*counter)\n",
    "        outputs_list.append(output)\n",
    "        counter += 1\n",
    "    \n",
    "    node_features = torch.stack(node_features_list, dim=0)\n",
    "    node_features = torch.reshape(node_features, (node_features.shape[0]*node_features.shape[1], node_features.shape[2]))\n",
    "    graphs = torch.cat(graph_list, 1)\n",
    "    outputs = torch.stack(outputs_list, dim=0)\n",
    "    \n",
    "    return node_features, graphs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83ea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=3, shuffle=True, collate_fn = graph_collate_fn)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size=3, shuffle=True, collate_fn = graph_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae02b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_batch(batch_num, num_nodes):\n",
    "    tensor_batch = torch.tensor([i for i in range(batch_num) for _ in range(num_nodes)]).to(device)\n",
    "    return tensor_batch\n",
    "\n",
    "def GAT_train(model, dataloader, epochs, num_nodes, lr = 1e-3, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    prev_batch_num = None\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            batch_num = batch[0].shape[0] // num_nodes\n",
    "            \n",
    "            if prev_batch_num != batch_num:\n",
    "                prev_batch_num = batch_num\n",
    "                tensor_batch = get_tensor_batch(prev_batch_num, num_nodes)\n",
    "            \n",
    "            node_features, graphs, outputs = batch \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            graphs = graphs.to(device)\n",
    "            node_features = node_features.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            out = model(node_features, graphs, tensor_batch)\n",
    "            loss = criterion(out, outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "          \n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "        \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('GATConv E/M classification Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45188f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from GAT import GAT\n",
    "model = GAT(1, 16, dataset.num_classes(), 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "716da8ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#GAT_train(model, training_dataloader, 500, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe52146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAT_test(model, dataloader, num_nodes):\n",
    "    test_losses = []\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    prev_batch_num = None\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        \n",
    "        batch_num = batch[0].shape[0] // num_nodes\n",
    "            \n",
    "        if prev_batch_num != batch_num:\n",
    "            prev_batch_num = batch_num\n",
    "            tensor_batch = get_tensor_batch(prev_batch_num, num_nodes)\n",
    "        \n",
    "        node_features, graphs, outputs = batch\n",
    "        \n",
    "        graphs = graphs.to(device)\n",
    "        node_features = node_features.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        \n",
    "        out = model(node_features, graphs, tensor_batch)\n",
    "            \n",
    "        loss = criterion(out, outputs)\n",
    "        \n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "    return sum(test_losses)/len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10337b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAT_test(model, testing_dataloader, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69e01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.linear2 = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2cc72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size=32, shuffle=True)\n",
    "mlp = MLP(dataset.num_nodes(), 16, dataset.num_classes()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46474081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_train(model, dataloader, epochs, lr = 1e-8, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        model = model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            node_features, _, outputs = batch\n",
    "            node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            out = model(node_features)\n",
    "            loss = criterion(out, outputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "            \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('MLP E/M classification Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d5d5d8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MLP_train(mlp, training_dataloader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab83a7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_test(model, dataloader):\n",
    "    test_losses = []\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        node_features, _, outputs = batch\n",
    "        node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        out = model(node_features)\n",
    "        loss = criterion(out, outputs)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "    return sum(test_losses)/len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa63521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP_test(mlp, testing_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421e107",
   "metadata": {},
   "source": [
    "# Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "168f433e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import torch\\nfrom torch.utils.data import Dataset\\nfrom torch_geometric.data import Data\\nfrom tqdm import tqdm\\n\\ndef get_all_protein_pairs(protein_list):\\n    protein_pairs = []\\n    for i in range(len(protein_list)):\\n        protein1 = protein_list[i]\\n        for j in range(i+1, len(protein_list)):\\n            protein2 = protein_list[j]\\n        \\n            protein_pairs.append((protein1, protein2))\\n            \\n    return protein_pairs\\n\\nclass Contrastive_Dataset(Dataset):\\n    def __init__(self, scRNA_data, string_2_protein):\\n        filename = '9606.protein.links.v12.0.txt'\\n\\n        file = open(filename, 'r')\\n        lines = file.readlines()\\n        lines.pop(0)\\n\\n        string_2_index = dict()\\n        counter = 0\\n        for string_id in string_2_protein:\\n            string_2_index[string_id] = counter\\n            counter += 1\\n\\n        list_network = list()\\n        \\n        self.train_node_features = list()\\n        self.train_list_outputs = list()\\n        \\n        self.test_node_features = list()\\n        self.test_list_outputs = list()\\n        \\n        self.val_node_features = list()\\n        self.val_list_outputs = list()\\n\\n        print('Getting network tensor...')\\n        for line in tqdm(lines):\\n            line = line.strip().split(' ')\\n\\n            if int(line[2]) >= 999:\\n\\n                try:\\n                    id1 = string_2_index[line[0]]\\n                    id2 = string_2_index[line[1]]\\n                    list_network.append([id1, id2])\\n                    list_network.append([id2, id1])\\n\\n                except KeyError:\\n                    continue\\n\\n        print('Getting node features tensor...')\\n        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\\n        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\\n        \\n        proteins = set([string_2_protein[string_id] for string_id in string_2_index])\\n        train_proteins, test_proteins, validate_proteins = np.split(proteins, [int(len(proteins)*0.7), int(len(proteins*0.9))])\\n        \\n        train_protein_pairs = get_all_protein_pairs(train_proteins)\\n        testing_protein_pairs = get_all_protein_pairs(test_proteins)\\n        validate_protein_pairs = get_all_protein_pairs(validate_proteins)\\n        \\n        #for \\n        \\n        for column in T0_column_vals:   \\n            self.train_node_features.append((scRNA_data.loc[protein_pair[0], column], scRNA_data.loc[protein_pair[1], column] for protein_pair in train_protein_pairs)\\n            self.train_list_outputs.append([1.0] for _ in range(len()))\\n        #print(self.node_features[0])                                                                                                                                                   \\n        for column in T8_column_vals:\\n            #print('Hello')                                                                                                                                                             \\n            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\\n            self.list_outputs.append([0,1])\\n\\n        \\n        self.edge_index = torch.tensor(list_network).t().contiguous()\\n        self.node_features = torch.tensor(self.node_features, dtype=torch.float)\\n        self.list_outputs = torch.tensor(self.list_outputs, dtype=torch.float)\\n\\n    def __getitem__(self, idx):\\n        graph = self.edge_index\\n        node_feature = torch.transpose(self.node_features[idx], 0, 1).t()\\n        output = self.list_outputs[idx]\\n\\n        #self.idx += 1                                                                                                                                                                  \\n        #if self.idx == len(self.node_features):                                                                                                                                        \\n            #self.idx = 0                                                                                                                                                               \\n\\n        return node_feature, graph, output\\n\\n    def __len__(self):\\n        return len(self.node_features)\\n\\n    def num_nodes(self):\\n        return self.node_features[0].shape[0]\\n\\n    def num_classes(self):\\n        return self.list_outputs[0].shape[0]\\n\\n    def num_features(self):\\n        return self.node_features[0].shape[1]\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_all_protein_pairs(protein_list):\n",
    "    protein_pairs = []\n",
    "    for i in range(len(protein_list)):\n",
    "        protein1 = protein_list[i]\n",
    "        for j in range(i+1, len(protein_list)):\n",
    "            protein2 = protein_list[j]\n",
    "        \n",
    "            protein_pairs.append((protein1, protein2))\n",
    "            \n",
    "    return protein_pairs\n",
    "\n",
    "class Contrastive_Dataset(Dataset):\n",
    "    def __init__(self, scRNA_data, string_2_protein):\n",
    "        filename = '9606.protein.links.v12.0.txt'\n",
    "\n",
    "        file = open(filename, 'r')\n",
    "        lines = file.readlines()\n",
    "        lines.pop(0)\n",
    "\n",
    "        string_2_index = dict()\n",
    "        counter = 0\n",
    "        for string_id in string_2_protein:\n",
    "            string_2_index[string_id] = counter\n",
    "            counter += 1\n",
    "\n",
    "        list_network = list()\n",
    "        \n",
    "        self.train_node_features = list()\n",
    "        self.train_list_outputs = list()\n",
    "        \n",
    "        self.test_node_features = list()\n",
    "        self.test_list_outputs = list()\n",
    "        \n",
    "        self.val_node_features = list()\n",
    "        self.val_list_outputs = list()\n",
    "\n",
    "        print('Getting network tensor...')\n",
    "        for line in tqdm(lines):\n",
    "            line = line.strip().split(' ')\n",
    "\n",
    "            if int(line[2]) >= 999:\n",
    "\n",
    "                try:\n",
    "                    id1 = string_2_index[line[0]]\n",
    "                    id2 = string_2_index[line[1]]\n",
    "                    list_network.append([id1, id2])\n",
    "                    list_network.append([id2, id1])\n",
    "\n",
    "                except KeyError:\n",
    "                    continue\n",
    "\n",
    "        print('Getting node features tensor...')\n",
    "        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\n",
    "        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\n",
    "        \n",
    "        proteins = set([string_2_protein[string_id] for string_id in string_2_index])\n",
    "        train_proteins, test_proteins, validate_proteins = np.split(proteins, [int(len(proteins)*0.7), int(len(proteins*0.9))])\n",
    "        \n",
    "        train_protein_pairs = get_all_protein_pairs(train_proteins)\n",
    "        testing_protein_pairs = get_all_protein_pairs(test_proteins)\n",
    "        validate_protein_pairs = get_all_protein_pairs(validate_proteins)\n",
    "        \n",
    "        #for \n",
    "        \n",
    "        for column in T0_column_vals:   \n",
    "            self.train_node_features.append((scRNA_data.loc[protein_pair[0], column], scRNA_data.loc[protein_pair[1], column] for protein_pair in train_protein_pairs)\n",
    "            self.train_list_outputs.append([1.0] for _ in range(len()))\n",
    "        #print(self.node_features[0])                                                                                                                                                   \n",
    "        for column in T8_column_vals:\n",
    "            #print('Hello')                                                                                                                                                             \n",
    "            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\n",
    "            self.list_outputs.append([0,1])\n",
    "\n",
    "        \n",
    "        self.edge_index = torch.tensor(list_network).t().contiguous()\n",
    "        self.node_features = torch.tensor(self.node_features, dtype=torch.float)\n",
    "        self.list_outputs = torch.tensor(self.list_outputs, dtype=torch.float)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.edge_index\n",
    "        node_feature = torch.transpose(self.node_features[idx], 0, 1).t()\n",
    "        output = self.list_outputs[idx]\n",
    "\n",
    "        #self.idx += 1                                                                                                                                                                  \n",
    "        #if self.idx == len(self.node_features):                                                                                                                                        \n",
    "            #self.idx = 0                                                                                                                                                               \n",
    "\n",
    "        return node_feature, graph, output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.node_features)\n",
    "\n",
    "    def num_nodes(self):\n",
    "        return self.node_features[0].shape[0]\n",
    "\n",
    "    def num_classes(self):\n",
    "        return self.list_outputs[0].shape[0]\n",
    "\n",
    "    def num_features(self):\n",
    "        return self.node_features[0].shape[1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56cf2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_dataset, batch_size=2, shuffle=True)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa59d2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = 'cpu'\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05ae4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT_Contrast(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads, dropout = 0.6)\n",
    "        self.output_layer1 = nn.Linear(hidden_channels*heads, 256)\n",
    "        self.output_layer2 = nn.Linear(256, 128)\n",
    "        self.output_layer3 = nn.Linear(128, 1)\n",
    "        #self.output_layer4 = nn.Linear(75360, 2)\n",
    "        self.cos = nn.CosineSimilarity(dim=0)\n",
    "        #self.gat2 = GATConv(in_channels, hidden_channels, heads, dropout = 0.6)\n",
    "\n",
    "    def forward(self, x1, edge_index1, x2, edge_index2):\n",
    "        x1 = self.gat1(x1, edge_index1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        x2 = self.gat1(x2, edge_index2)\n",
    "        x2 = F.relu(x2)\n",
    "    \n",
    "        x1 = self.output_layer1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        x2 = self.output_layer1(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.output_layer2(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        x2 = self.output_layer2(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.output_layer3(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        \n",
    "        x2 = self.output_layer3(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        #print(x1)\n",
    "        #print(x2)\n",
    "        x = self.cos(x1, x2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "236fd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3999bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9e2f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "def GAT_contrast_train(model, dataloader, epochs, num_nodes, lr = 1e-6, weight_decay = 5e-4):\n",
    "    #torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    #criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            try:\n",
    "                x1, edge_index1 = batch[0][0].to(device), batch[1][0].to(device)\n",
    "                x2, edge_index2 = batch[0][1].to(device), batch[1][1].to(device)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            \n",
    "            if torch.equal(batch[2][0], batch[2][1]):\n",
    "                outputs = torch.tensor([1]).to(device)\n",
    "            else:\n",
    "                outputs = torch.tensor([0]).to(device)\n",
    "            #print(outputs)\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            out = model(x1, edge_index1, x2, edge_index2)\n",
    "            #print(out, outputs)\n",
    "            loss = criterion(out, outputs)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        #print(sum(losses)/len(losses))\n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "        \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('GATConv Contrastive Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d745fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_contrast = GAT_Contrast(1, 16, dataset.num_nodes(), 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5f17737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19714/837141678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGAT_contrast_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgat_contrast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscRNA_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_19714/1467252552.py\u001b[0m in \u001b[0;36mGAT_contrast_train\u001b[0;34m(model, dataloader, epochs, num_nodes, lr, weight_decay)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#print(out, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;31m#print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2733\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 1 is out of bounds."
     ]
    }
   ],
   "source": [
    "GAT_contrast_train(gat_contrast, training_dataloader, 500, scRNA_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAT_contrast_test(model, dataloader):\n",
    "    torch.cuda.empty_cache()\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    losses = []\n",
    "    \n",
    "        \n",
    "    for batch in dataloader:\n",
    "        try:\n",
    "            x1, edge_index1 = batch[0][0].to(device), batch[1][0].to(device)\n",
    "            x2, edge_index2 = batch[0][1].to(device), batch[1][1].to(device)\n",
    "        except IndexError:\n",
    "            continue\n",
    "            \n",
    "        if torch.equal(batch[2][0], batch[2][1]):\n",
    "            outputs = torch.tensor([1.0]).to(device)\n",
    "        else:\n",
    "            outputs = torch.tensor([0.0]).to(device)\n",
    "    \n",
    "        out = model(x1, edge_index1, x2, edge_index2)\n",
    "        loss = criterion(out, outputs)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    print(sum(losses)/len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAT_contrast_test(gat_contrast, testing_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b354dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Contrast(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_channels, hidden_channels)\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_channels, 128)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "        self.linear4 = nn.Linear(64, 1)\n",
    "        #self.linear5 = nn.Linear(64*18840, 2)\n",
    "        self.cos = nn.CosineSimilarity(dim=0)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.linear1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear1(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.linear2(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear2(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.linear3(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear3(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        \n",
    "        x1 = self.linear4(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x2 = self.linear4(x2)\n",
    "        x2 = F.relu(x2)\n",
    "        #print(x1,x2)\n",
    "        x = self.cos(x1, x2)\n",
    "        #print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_contrast = MLP_Contrast(1, 16, dataset.num_nodes()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_contrast_train(model, dataloader, epochs, lr = 1e-6, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        model = model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            node_features, _, outputs = batch\n",
    "            #print(node_features.shape)\n",
    "            try:\n",
    "                x1, x2 = node_features\n",
    "            except:\n",
    "                continue\n",
    "            x1 = x1.to(device)\n",
    "            x2 = x2.to(device)\n",
    "            \n",
    "            if torch.equal(batch[2][0], batch[2][1]):\n",
    "                outputs = torch.tensor([1.0]).to(device)\n",
    "            else:\n",
    "                outputs = torch.tensor([0.0]).to(device)\n",
    "                \n",
    "            #node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            out = model(x1, x2)\n",
    "            loss = criterion(out, outputs)\n",
    "            #print(out, outputs)\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "        print(all_losses[-1])\n",
    "            \n",
    "    plt.plot([i for i in range(1, (len(all_losses)+1))], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('MLP E/M classification Training') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f33b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLP_contrast_train(mlp_contrast, training_dataloader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_contrast_test(model, dataloader):\n",
    "    test_losses = []\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        node_features, _, outputs = batch\n",
    "        #node_features = torch.reshape(node_features, (node_features.shape[0], node_features.shape[1])).to(device)\n",
    "        try:\n",
    "            x1, x2 = node_features\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        \n",
    "        if torch.equal(batch[2][0], batch[2][1]):\n",
    "            outputs = torch.tensor([1.0]).to(device)\n",
    "        else:\n",
    "            outputs = torch.tensor([0.0]).to(device)\n",
    "        \n",
    "        outputs = outputs.to(device)\n",
    "        out = model(x1, x2)\n",
    "        loss = criterion(out, outputs)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "    return sum(test_losses)/len(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a97886",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_contrast_test(mlp_contrast, testing_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c0cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
