{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4cd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429182e7",
   "metadata": {},
   "source": [
    "# Useful Links\n",
    "Implementing data object for neural networks:\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "\n",
    "Writing a custom dataset class: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Writing a GAT Class example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py\n",
    "\n",
    "Dataloaders for Batch Training: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb818778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26364"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = pd.read_csv('GSE200981_scRNAseq_processed.tsv', sep='\\t')\n",
    "scRNA_data.index = scRNA_data['Gene.names']\n",
    "scRNA_data = scRNA_data.drop('Gene.names', axis=1)\n",
    "len(scRNA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d591b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping string to protein names\n",
    "string_api_url = \"https://string-db.org/api\"\n",
    "output_format = \"tsv-no-header\"\n",
    "method = \"get_string_ids\"\n",
    "\n",
    "params = {\n",
    "\n",
    "    \"identifiers\" : \"\\r\".join(list(scRNA_data.index)), # your protein list\n",
    "    \"limit\": 1,\n",
    "    \"echo_query\": 1,\n",
    "    \"species\" : 9606, # species NCBI identifier \n",
    "    \"caller_identity\" : \"www.awesome_app.org\" # your app name\n",
    "\n",
    "}\n",
    "\n",
    "request_url = \"/\".join([string_api_url, output_format, method])\n",
    "\n",
    "results = requests.post(request_url, data=params)\n",
    "\n",
    "\n",
    "protein_2_string = dict()\n",
    "string_2_protein = dict()\n",
    "\n",
    "for line in results.text.strip().split(\"\\n\"):\n",
    "    l = line.split(\"\\t\")\n",
    "    protein_identifier, string_identifier = l[0], l[2]\n",
    "    protein_2_string[protein_identifier] = string_identifier\n",
    "    string_2_protein[string_identifier] = protein_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acda1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_T0</th>\n",
       "      <th>V2_T0</th>\n",
       "      <th>V3_T0</th>\n",
       "      <th>V4_T0</th>\n",
       "      <th>V5_T0</th>\n",
       "      <th>V6_T0</th>\n",
       "      <th>V7_T0</th>\n",
       "      <th>V8_T0</th>\n",
       "      <th>V9_T0</th>\n",
       "      <th>V10_T0</th>\n",
       "      <th>...</th>\n",
       "      <th>V247_T7</th>\n",
       "      <th>V248_T7</th>\n",
       "      <th>V249_T7</th>\n",
       "      <th>V250_T7</th>\n",
       "      <th>V251_T7</th>\n",
       "      <th>V252_T7</th>\n",
       "      <th>V253_T7</th>\n",
       "      <th>V254_T7</th>\n",
       "      <th>V255_T7</th>\n",
       "      <th>V256_T7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene.names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows × 2125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1_T0  V2_T0  V3_T0  V4_T0  V5_T0  V6_T0  V7_T0  V8_T0  V9_T0  \\\n",
       "Gene.names                                                                  \n",
       "OR4F5           0      0      0      0      0      0      0      0      0   \n",
       "OR4F3           0      0      0      0      0      0      0      0      0   \n",
       "OR4F29          0      0      0      0      0      0      0      0      0   \n",
       "OR4F16          0      0      0      0      0      0      0      0      0   \n",
       "SAMD11          0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "DAZ1            0      0      0      0      0      0      0      0      0   \n",
       "DAZ3            0      0      0      0      0      0      0      0      0   \n",
       "DAZ2            0      0      0      0      0      0      0      0      0   \n",
       "CDY1B           0      0      0      0      0      0      0      0      0   \n",
       "CDY1            0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "            V10_T0  ...  V247_T7  V248_T7  V249_T7  V250_T7  V251_T7  V252_T7  \\\n",
       "Gene.names          ...                                                         \n",
       "OR4F5            0  ...        0        0        0        0        0        0   \n",
       "OR4F3            0  ...        0        0        0        0        0        0   \n",
       "OR4F29           0  ...        0        0        0        0        0        0   \n",
       "OR4F16           0  ...        0        0        0        0        0        0   \n",
       "SAMD11           0  ...        0        0        0        0        0        0   \n",
       "...            ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "DAZ1             0  ...        0        0        0        0        0        0   \n",
       "DAZ3             0  ...        0        0        0        0        0        0   \n",
       "DAZ2             0  ...        0        0        0        0        0        0   \n",
       "CDY1B            0  ...        0        0        0        0        0        0   \n",
       "CDY1             0  ...        0        0        0        0        0        0   \n",
       "\n",
       "            V253_T7  V254_T7  V255_T7  V256_T7  \n",
       "Gene.names                                      \n",
       "OR4F5             0        0        0        0  \n",
       "OR4F3             0        0        0        0  \n",
       "OR4F29            0        0        0        0  \n",
       "OR4F16            0        0        0        0  \n",
       "SAMD11            0        0        0        0  \n",
       "...             ...      ...      ...      ...  \n",
       "DAZ1              0        0        0        0  \n",
       "DAZ3              0        0        0        0  \n",
       "DAZ2              0        0        0        0  \n",
       "CDY1B             0        0        0        0  \n",
       "CDY1              0        0        0        0  \n",
       "\n",
       "[18840 rows x 2125 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = scRNA_data.loc[list(protein_2_string.keys())]\n",
    "scRNA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d8c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13715404/13715404 [00:10<00:00, 1349892.61it/s]\n"
     ]
    }
   ],
   "source": [
    "#Getting network pairs from interaction file\n",
    "file = open('9606.protein.links.v12.0.txt', 'r')\n",
    "lines = file.readlines()\n",
    "lines.pop(0)\n",
    "\n",
    "network_pairs = set()\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = line.strip().split(' ')\n",
    "    #print(line)\n",
    "    \n",
    "    if int(line[2]) >= 700:\n",
    "    \n",
    "        try:\n",
    "            p1 = string_2_protein[line[0]]\n",
    "            p2 = string_2_protein[line[1]]\n",
    "            \n",
    "            network_pairs.add((p1, p2))\n",
    "        \n",
    "        except KeyError:\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284f7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3573dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class GAT(torch.nn.Module):\\n    def __init__(self, in_channels, hidden_channels, out_channels, heads):\\n        super().__init__()\\n        \\n        self.conv1 = GATConv(in_channels, out_channels, heads, dropout = 0.6)\\n        self.output_layer = nn.Linear(hidden_channels*out_channels, out_channels)\\n        #self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0.6)\\n        #print(self.conv1.weight.dtype)\\n        \\n    def forward(self, x, edge_index):\\n        #x = F.dropout(x, p=0.6)\\n        x = self.conv1(x, edge_index)\\n        #print(x.size())\\n        x = torch.flatten(x)\\n        x = self.output_layer(x)\\n        #print(x.size())\\n        x = F.softmax(x)\\n        #x = F.dropout(x, p=0.6)\\n        #x = self.conv2(x, edge_index)\\n        return x'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "\"\"\"class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, out_channels, heads, dropout = 0.6)\n",
    "        self.output_layer = nn.Linear(hidden_channels*out_channels, out_channels)\n",
    "        #self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "        #print(self.conv1.weight.dtype)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        #x = F.dropout(x, p=0.6)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        #print(x.size())\n",
    "        x = torch.flatten(x)\n",
    "        x = self.output_layer(x)\n",
    "        #print(x.size())\n",
    "        x = F.softmax(x)\n",
    "        #x = F.dropout(x, p=0.6)\n",
    "        #x = self.conv2(x, edge_index)\n",
    "        return x\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592b9264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class EMT_Dataset(Dataset):\\n    def __init__(self, filename):\\n        filename = '9606.protein.links.v12.0.txt'\\n        \\n        file = open(filename, 'r')\\n        lines = file.readlines()\\n        lines.pop(0)\\n    \\n        string_2_index = dict()\\n        counter = 0\\n        for string_id in string_2_protein:\\n            string_2_index[string_id] = counter\\n            counter += 1\\n            \\n        list_network = list()\\n        self.node_features = list()\\n        self.list_outputs = list()\\n    \\n        print('Getting network tensor...')\\n        for line in tqdm(lines):\\n            line = line.strip().split(' ')\\n    \\n            if int(line[2]) >= 999:\\n    \\n                try:\\n                    id1 = string_2_index[line[0]]\\n                    id2 = string_2_index[line[1]]\\n                    list_network.append([id1, id2])\\n                    list_network.append([id2, id1])\\n        \\n                except KeyError:\\n                    continue\\n    \\n        print('Getting node features tensor...')\\n        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\\n        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\\n        #print(T8_column_vals)\\n        proteins = [string_2_protein[string_id] for string_id in string_2_index]\\n        \\n        for column in T0_column_vals:\\n            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\\n            self.list_outputs.append([1,0])\\n        #print(self.node_features[0])\\n        for column in T8_column_vals:\\n            #print('Hello')\\n            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\\n            self.list_outputs.append([0,1])\\n        \\n        #print([0, 1] in self.list_outputs)\\n        #print(len(self.node_features[0]))\\n        self.edge_index = torch.tensor(list_network).t().contiguous()\\n        self.node_features = torch.tensor(self.node_features, dtype=torch.float)\\n        self.list_outputs = torch.tensor(self.list_outputs, dtype=torch.float)                            \\n    \\n    def __getitem__(self, idx):\\n        graph = self.edge_index\\n        node_feature = torch.transpose(self.node_features[idx], 0, 1).t()\\n        output = self.list_outputs[idx]\\n        \\n        #self.idx += 1\\n        #if self.idx == len(self.node_features):\\n            #self.idx = 0\\n        \\n        return graph, node_feature, output\\n    \\n    def __len__(self):\\n        return len(self.node_features)\\n    \\n    def num_features(self):\\n        return self.node_features[0].shape[0]\\n    \\n    def num_classes(self):\\n        return self.list_outputs[0].shape[0]\\n    \\n    def shuffle(self):\\n        temp = list(zip(self.node_features, self.list_outputs))\\n        random.shuffle(temp)\\n        self.node_features, self.list_outputs = zip(*temp)\\n        self.node_features, self.list_outputs = list(self.node_features), list(self.list_outputs)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class EMT_Dataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        filename = '9606.protein.links.v12.0.txt'\n",
    "        \n",
    "        file = open(filename, 'r')\n",
    "        lines = file.readlines()\n",
    "        lines.pop(0)\n",
    "    \n",
    "        string_2_index = dict()\n",
    "        counter = 0\n",
    "        for string_id in string_2_protein:\n",
    "            string_2_index[string_id] = counter\n",
    "            counter += 1\n",
    "            \n",
    "        list_network = list()\n",
    "        self.node_features = list()\n",
    "        self.list_outputs = list()\n",
    "    \n",
    "        print('Getting network tensor...')\n",
    "        for line in tqdm(lines):\n",
    "            line = line.strip().split(' ')\n",
    "    \n",
    "            if int(line[2]) >= 999:\n",
    "    \n",
    "                try:\n",
    "                    id1 = string_2_index[line[0]]\n",
    "                    id2 = string_2_index[line[1]]\n",
    "                    list_network.append([id1, id2])\n",
    "                    list_network.append([id2, id1])\n",
    "        \n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "        print('Getting node features tensor...')\n",
    "        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\n",
    "        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\n",
    "        #print(T8_column_vals)\n",
    "        proteins = [string_2_protein[string_id] for string_id in string_2_index]\n",
    "        \n",
    "        for column in T0_column_vals:\n",
    "            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\n",
    "            self.list_outputs.append([1,0])\n",
    "        #print(self.node_features[0])\n",
    "        for column in T8_column_vals:\n",
    "            #print('Hello')\n",
    "            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\n",
    "            self.list_outputs.append([0,1])\n",
    "        \n",
    "        #print([0, 1] in self.list_outputs)\n",
    "        #print(len(self.node_features[0]))\n",
    "        self.edge_index = torch.tensor(list_network).t().contiguous()\n",
    "        self.node_features = torch.tensor(self.node_features, dtype=torch.float)\n",
    "        self.list_outputs = torch.tensor(self.list_outputs, dtype=torch.float)                            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.edge_index\n",
    "        node_feature = torch.transpose(self.node_features[idx], 0, 1).t()\n",
    "        output = self.list_outputs[idx]\n",
    "        \n",
    "        #self.idx += 1\n",
    "        #if self.idx == len(self.node_features):\n",
    "            #self.idx = 0\n",
    "        \n",
    "        return graph, node_feature, output\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.node_features)\n",
    "    \n",
    "    def num_features(self):\n",
    "        return self.node_features[0].shape[0]\n",
    "    \n",
    "    def num_classes(self):\n",
    "        return self.list_outputs[0].shape[0]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        temp = list(zip(self.node_features, self.list_outputs))\n",
    "        random.shuffle(temp)\n",
    "        self.node_features, self.list_outputs = zip(*temp)\n",
    "        self.node_features, self.list_outputs = list(self.node_features), list(self.list_outputs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13715404 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting network tensor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13715404/13715404 [00:08<00:00, 1553990.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting node features tensor...\n"
     ]
    }
   ],
   "source": [
    "from dataset import EMT_Dataset\n",
    "dataset = EMT_Dataset(scRNA_data, string_2_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63690db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epochs, lr = 1e-8, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    all_losses = []\n",
    "    \n",
    "    for _ in tqdm(range(epochs)):\n",
    "        model = model.train()\n",
    "        losses = []\n",
    "        \n",
    "        for (graph, node_features, output) in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #graph, node_features, output = dataset.__getitem__(i)\n",
    "            graph = graph.to(device)\n",
    "            node_features = node_features.to(device)\n",
    "            output = output.to(device)\n",
    "    \n",
    "            out = model(node_features, graph)\n",
    "            #print(out, output)\n",
    "            loss = criterion(out, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss)\n",
    "            \n",
    "        all_losses.append(sum(losses)/len(losses))\n",
    "        \n",
    "    plt.plot([i for i in range(1, epochs+1)], all_losses)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('GATConv E/M classification Training')\n",
    "    plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45188f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAT import GAT\n",
    "model = GAT(1, dataset.num_features(), dataset.num_classes(), 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde29c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_features(), dataset.num_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716da8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(model, dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52146b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
