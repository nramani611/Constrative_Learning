{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4cd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429182e7",
   "metadata": {},
   "source": [
    "# Useful Links\n",
    "Implementing data object for neural networks:\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html\n",
    "\n",
    "Writing a custom dataset class: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "Writing a GAT Class example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb818778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26364"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = pd.read_csv('GSE200981_scRNAseq_processed.tsv', sep='\\t')\n",
    "scRNA_data.index = scRNA_data['Gene.names']\n",
    "scRNA_data = scRNA_data.drop('Gene.names', axis=1)\n",
    "len(scRNA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d591b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping string to protein names\n",
    "string_api_url = \"https://string-db.org/api\"\n",
    "output_format = \"tsv-no-header\"\n",
    "method = \"get_string_ids\"\n",
    "\n",
    "params = {\n",
    "\n",
    "    \"identifiers\" : \"\\r\".join(list(scRNA_data.index)), # your protein list\n",
    "    \"limit\": 1,\n",
    "    \"echo_query\": 1,\n",
    "    \"species\" : 9606, # species NCBI identifier \n",
    "    \"caller_identity\" : \"www.awesome_app.org\" # your app name\n",
    "\n",
    "}\n",
    "\n",
    "request_url = \"/\".join([string_api_url, output_format, method])\n",
    "\n",
    "results = requests.post(request_url, data=params)\n",
    "\n",
    "\n",
    "protein_2_string = dict()\n",
    "string_2_protein = dict()\n",
    "\n",
    "for line in results.text.strip().split(\"\\n\"):\n",
    "    l = line.split(\"\\t\")\n",
    "    protein_identifier, string_identifier = l[0], l[2]\n",
    "    protein_2_string[protein_identifier] = string_identifier\n",
    "    string_2_protein[string_identifier] = protein_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4acda1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1_T0</th>\n",
       "      <th>V2_T0</th>\n",
       "      <th>V3_T0</th>\n",
       "      <th>V4_T0</th>\n",
       "      <th>V5_T0</th>\n",
       "      <th>V6_T0</th>\n",
       "      <th>V7_T0</th>\n",
       "      <th>V8_T0</th>\n",
       "      <th>V9_T0</th>\n",
       "      <th>V10_T0</th>\n",
       "      <th>...</th>\n",
       "      <th>V247_T7</th>\n",
       "      <th>V248_T7</th>\n",
       "      <th>V249_T7</th>\n",
       "      <th>V250_T7</th>\n",
       "      <th>V251_T7</th>\n",
       "      <th>V252_T7</th>\n",
       "      <th>V253_T7</th>\n",
       "      <th>V254_T7</th>\n",
       "      <th>V255_T7</th>\n",
       "      <th>V256_T7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene.names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OR4F5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OR4F16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMD11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAZ2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1B</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDY1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18840 rows × 2125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            V1_T0  V2_T0  V3_T0  V4_T0  V5_T0  V6_T0  V7_T0  V8_T0  V9_T0  \\\n",
       "Gene.names                                                                  \n",
       "OR4F5           0      0      0      0      0      0      0      0      0   \n",
       "OR4F3           0      0      0      0      0      0      0      0      0   \n",
       "OR4F29          0      0      0      0      0      0      0      0      0   \n",
       "OR4F16          0      0      0      0      0      0      0      0      0   \n",
       "SAMD11          0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "DAZ1            0      0      0      0      0      0      0      0      0   \n",
       "DAZ3            0      0      0      0      0      0      0      0      0   \n",
       "DAZ2            0      0      0      0      0      0      0      0      0   \n",
       "CDY1B           0      0      0      0      0      0      0      0      0   \n",
       "CDY1            0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "            V10_T0  ...  V247_T7  V248_T7  V249_T7  V250_T7  V251_T7  V252_T7  \\\n",
       "Gene.names          ...                                                         \n",
       "OR4F5            0  ...        0        0        0        0        0        0   \n",
       "OR4F3            0  ...        0        0        0        0        0        0   \n",
       "OR4F29           0  ...        0        0        0        0        0        0   \n",
       "OR4F16           0  ...        0        0        0        0        0        0   \n",
       "SAMD11           0  ...        0        0        0        0        0        0   \n",
       "...            ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "DAZ1             0  ...        0        0        0        0        0        0   \n",
       "DAZ3             0  ...        0        0        0        0        0        0   \n",
       "DAZ2             0  ...        0        0        0        0        0        0   \n",
       "CDY1B            0  ...        0        0        0        0        0        0   \n",
       "CDY1             0  ...        0        0        0        0        0        0   \n",
       "\n",
       "            V253_T7  V254_T7  V255_T7  V256_T7  \n",
       "Gene.names                                      \n",
       "OR4F5             0        0        0        0  \n",
       "OR4F3             0        0        0        0  \n",
       "OR4F29            0        0        0        0  \n",
       "OR4F16            0        0        0        0  \n",
       "SAMD11            0        0        0        0  \n",
       "...             ...      ...      ...      ...  \n",
       "DAZ1              0        0        0        0  \n",
       "DAZ3              0        0        0        0  \n",
       "DAZ2              0        0        0        0  \n",
       "CDY1B             0        0        0        0  \n",
       "CDY1              0        0        0        0  \n",
       "\n",
       "[18840 rows x 2125 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scRNA_data = scRNA_data.loc[list(protein_2_string.keys())]\n",
    "scRNA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d8c4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13715404/13715404 [00:10<00:00, 1296940.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#Getting network pairs from interaction file\n",
    "file = open('9606.protein.links.v12.0.txt', 'r')\n",
    "lines = file.readlines()\n",
    "lines.pop(0)\n",
    "\n",
    "network_pairs = set()\n",
    "\n",
    "for line in tqdm(lines):\n",
    "    line = line.strip().split(' ')\n",
    "    #print(line)\n",
    "    \n",
    "    if int(line[2]) >= 700:\n",
    "    \n",
    "        try:\n",
    "            p1 = string_2_protein[line[0]]\n",
    "            p2 = string_2_protein[line[1]]\n",
    "            \n",
    "            network_pairs.add((p1, p2))\n",
    "        \n",
    "        except KeyError:\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284f7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e3573dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = GATConv(in_channels, out_channels, heads, dropout = 0.6)\n",
    "        self.output_layer = nn.Linear(hidden_channels*out_channels, out_channels)\n",
    "        #self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "        #print(self.conv1.weight.dtype)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        #x = F.dropout(x, p=0.6)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        #print(x.size())\n",
    "        x = torch.flatten(x)\n",
    "        x = self.output_layer(x)\n",
    "        #print(x.size())\n",
    "        x = F.softmax(x)\n",
    "        #x = F.dropout(x, p=0.6)\n",
    "        #x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592b9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '9606.protein.links.v12.0.txt'\n",
    "\n",
    "class EMT_Dataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        #self.idx = 0\n",
    "        \n",
    "        file = open(filename, 'r')\n",
    "        lines = file.readlines()\n",
    "        lines.pop(0)\n",
    "    \n",
    "        string_2_index = dict()\n",
    "        counter = 0\n",
    "        for string_id in string_2_protein:\n",
    "            string_2_index[string_id] = counter\n",
    "            counter += 1\n",
    "            \n",
    "        list_network = list()\n",
    "        self.node_features = list()\n",
    "        self.list_outputs = list()\n",
    "    \n",
    "        print('Getting network tensor...')\n",
    "        for line in tqdm(lines):\n",
    "            line = line.strip().split(' ')\n",
    "    \n",
    "            if int(line[2]) >= 999:\n",
    "    \n",
    "                try:\n",
    "                    id1 = string_2_index[line[0]]\n",
    "                    id2 = string_2_index[line[1]]\n",
    "                    list_network.append([id1, id2])\n",
    "                    list_network.append([id2, id1])\n",
    "        \n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "        print('Getting node features tensor...')\n",
    "        T0_column_vals = [column for column in scRNA_data.columns if 'T0' in column]\n",
    "        T8_column_vals = [column for column in scRNA_data.columns if 'T7' in column]\n",
    "        #print(T8_column_vals)\n",
    "        proteins = [string_2_protein[string_id] for string_id in string_2_index]\n",
    "        \n",
    "        for column in T0_column_vals:\n",
    "            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\n",
    "            self.list_outputs.append([1,0])\n",
    "        #print(self.node_features[0])\n",
    "        for column in T8_column_vals:\n",
    "            #print('Hello')\n",
    "            self.node_features.append([[scRNA_data.loc[protein, column]] for protein in proteins])\n",
    "            self.list_outputs.append([0,1])\n",
    "        \n",
    "        #print([0, 1] in self.list_outputs)\n",
    "        #print(len(self.node_features[0]))\n",
    "        self.edge_index = torch.tensor(list_network).t().contiguous()\n",
    "        self.node_features = torch.tensor(self.node_features, dtype=torch.float)\n",
    "        self.list_outputs = torch.tensor(self.list_outputs, dtype=torch.float)                            \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.edge_index\n",
    "        node_feature = torch.transpose(self.node_features[idx], 0, 1).t()\n",
    "        output = self.list_outputs[idx]\n",
    "        \n",
    "        #self.idx += 1\n",
    "        #if self.idx == len(self.node_features):\n",
    "            #self.idx = 0\n",
    "        \n",
    "        return graph, node_feature, output\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.node_features)\n",
    "    \n",
    "    def num_features(self):\n",
    "        return self.node_features[0].shape[0]\n",
    "    \n",
    "    def num_classes(self):\n",
    "        return self.list_outputs[0].shape[0]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        temp = list(zip(self.node_features, self.list_outputs))\n",
    "        random.shuffle(temp)\n",
    "        self.node_features, self.list_outputs = zip(*temp)\n",
    "        self.node_features, self.list_outputs = list(self.node_features), list(self.list_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be15c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 151664/13715404 [00:00<00:08, 1516507.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting network tensor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13715404/13715404 [00:08<00:00, 1567171.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting node features tensor...\n"
     ]
    }
   ],
   "source": [
    "dataset = EMT_Dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c98c894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae02b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, epochs, lr = 1e-8, weight_decay = 5e-4):\n",
    "    torch.cuda.empty_cache()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        model = model.train()\n",
    "        \n",
    "        for i in range(len(dataset)):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            graph, node_features, output = dataset.__getitem__(i)\n",
    "            graph = graph.to(device)\n",
    "            node_features = node_features.to(device)\n",
    "    \n",
    "            out = model(node_features, graph)\n",
    "            print(out, output)\n",
    "            loss = criterion(out, output)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45188f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(1, dataset.num_features(), dataset.num_classes(), 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bde29c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18840, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_features(), dataset.num_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "716da8ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-89fd749cb75c>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9575, 0.0425], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0018046649638563395\n",
      "tensor([0.6596, 0.3404], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.43507251143455505\n",
      "tensor([0.9414, 0.0586], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0034291474148631096\n",
      "tensor([9.9941e-01, 5.9134e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.496461999930034e-07\n",
      "tensor([0.4308, 0.5692], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.18557988107204437\n",
      "tensor([0.4718, 0.5282], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2226019650697708\n",
      "tensor([0.4694, 0.5306], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.28156009316444397\n",
      "tensor([0.0139, 0.9861], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0001934048777911812\n",
      "tensor([0.9948, 0.0052], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9895423054695129\n",
      "tensor([0.1692, 0.8308], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.028622418642044067\n",
      "tensor([0.9859, 0.0141], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00019936580793000758\n",
      "tensor([9.9999e-01, 9.6870e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.353762209229899e-11\n",
      "tensor([8.5973e-04, 9.9914e-01], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "7.391448662019684e-07\n",
      "tensor([9.9975e-01, 2.4859e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.180157186008728e-08\n",
      "tensor([0.3615, 0.6385], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1307031214237213\n",
      "tensor([0.9985, 0.0015], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.2428835109167267e-06\n",
      "tensor([9.9904e-01, 9.6023e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9980803728103638\n",
      "tensor([0.9664, 0.0336], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9338329434394836\n",
      "tensor([9.9998e-01, 1.5977e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999680519104004\n",
      "tensor([0.9576, 0.0424], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0017969307955354452\n",
      "tensor([0.9877, 0.0123], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.000152207154314965\n",
      "tensor([0.9736, 0.0264], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.000696670962497592\n",
      "tensor([0.6931, 0.3069], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09417812526226044\n",
      "tensor([0.7494, 0.2506], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.06280895322561264\n",
      "tensor([0.6926, 0.3074], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09448595345020294\n",
      "tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.34018972516059875\n",
      "tensor([0.9955, 0.0045], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.0570783817674965e-05\n",
      "tensor([0.4894, 0.5106], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.23949621617794037\n",
      "tensor([0.2753, 0.7247], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5251994729042053\n",
      "tensor([0.9935, 0.0065], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.25017460656818e-05\n",
      "tensor([0.9795, 0.0205], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00041908567072823644\n",
      "tensor([0.9326, 0.0674], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004548004828393459\n",
      "tensor([0.9873, 0.0127], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9747587442398071\n",
      "tensor([0.3246, 0.6754], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.4561655521392822\n",
      "tensor([0.9990, 0.0010], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.009724655887112e-06\n",
      "tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7769613265991211\n",
      "tensor([0.3622, 0.6378], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.13119865953922272\n",
      "tensor([9.9939e-01, 6.0951e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.715088894296059e-07\n",
      "tensor([1.0000e+00, 7.0555e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999985694885254\n",
      "tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3838389349984936e-05\n",
      "tensor([0.8692, 0.1308], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7554625272750854\n",
      "tensor([0.4870, 0.5130], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.23718413710594177\n",
      "tensor([0.9758, 0.0242], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0005853429902344942\n",
      "tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9887474179267883\n",
      "tensor([0.9624, 0.0376], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0014169446658343077\n",
      "tensor([0.5890, 0.4110], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3468732535839081\n",
      "tensor([1.0000e+00, 3.2187e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1574900380621062e-13\n",
      "tensor([9.9997e-01, 2.8889e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.333975731744658e-10\n",
      "tensor([1.0000e+00, 1.6406e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.7385220827125245e-12\n",
      "tensor([0.1042, 0.8958], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8023697733879089\n",
      "tensor([9.9997e-01, 3.2054e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.027880003334758e-09\n",
      "tensor([9.9957e-01, 4.2792e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8310751670469472e-07\n",
      "tensor([0.9983, 0.0017], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.0355474791576853e-06\n",
      "tensor([0.9877, 0.0123], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00015216651081573218\n",
      "tensor([0.9226, 0.0774], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005987378768622875\n",
      "tensor([0.8744, 0.1256], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7645517587661743\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9911295175552368\n",
      "tensor([1.0000e+00, 2.5436e-09], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.6408, 0.3592], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4106803238391876\n",
      "tensor([0.9843, 0.0157], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00024650173145346344\n",
      "tensor([0.4772, 0.5228], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.22770032286643982\n",
      "tensor([0.9969, 0.0031], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.878708624455612e-06\n",
      "tensor([0.9987, 0.0013], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.7670013221504632e-06\n",
      "tensor([0.8756, 0.1244], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.015477700158953667\n",
      "tensor([9.9998e-01, 1.8759e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.510999824207772e-10\n",
      "tensor([9.9985e-01, 1.5350e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.35692425576417e-08\n",
      "tensor([9.9973e-01, 2.7368e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9994527101516724\n",
      "tensor([1.0000e+00, 6.1874e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.690557245656506e-13\n",
      "tensor([0.7539, 0.2461], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.568374752998352\n",
      "tensor([9.9973e-01, 2.6819e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.191883355517348e-08\n",
      "tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.0791467250091955e-05\n",
      "tensor([0.1910, 0.8090], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.03648197278380394\n",
      "tensor([0.9971, 0.0029], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9942558407783508\n",
      "tensor([0.9556, 0.0444], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9130797386169434\n",
      "tensor([9.9998e-01, 1.9507e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.8137404345661707e-10\n",
      "tensor([0.9821, 0.0179], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9646114110946655\n",
      "tensor([1.0000e+00, 1.1624e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3861415507976978e-14\n",
      "tensor([0.9905, 0.0095], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.029681677930057e-05\n",
      "tensor([0.9898, 0.0102], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00010447980457684025\n",
      "tensor([0.6962, 0.3038], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09229007363319397\n",
      "tensor([9.9915e-01, 8.4934e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.21403694114997e-07\n",
      "tensor([0.9870, 0.0130], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00017023984401021153\n",
      "tensor([0.5829, 0.4171], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.1740109920501709\n",
      "tensor([0.8918, 0.1082], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.011703386902809143\n",
      "tensor([9.9998e-01, 2.2887e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.238394717999029e-10\n",
      "tensor([9.9983e-01, 1.6771e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.8129409912480696e-08\n",
      "tensor([9.9994e-01, 5.5044e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.031552564536355e-09\n",
      "tensor([0.9987, 0.0013], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.997381329536438\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2377687426123885e-06\n",
      "tensor([0.5872, 0.4128], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3448559641838074\n",
      "tensor([9.9996e-01, 4.0978e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6804342362064517e-09\n",
      "tensor([1.0000e+00, 1.2405e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.4799910429130758e-12\n",
      "tensor([0.5054, 0.4946], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2554698884487152\n",
      "tensor([0.6070, 0.3930], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.36848875880241394\n",
      "tensor([0.9979, 0.0021], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9958581328392029\n",
      "tensor([0.9914, 0.0086], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9827816486358643\n",
      "tensor([9.9975e-01, 2.5091e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9994982481002808\n",
      "tensor([1.0000e+00, 1.0805e-11], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.837505696496897e-23\n",
      "tensor([9.9996e-01, 4.3473e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.891567125156257e-09\n",
      "tensor([9.9985e-01, 1.4680e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997063279151917\n",
      "tensor([2.0994e-04, 9.9979e-01], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "4.405874420854161e-08\n",
      "tensor([0.9505, 0.0495], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9034637212753296\n",
      "tensor([0.9112, 0.0888], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00788793247193098\n",
      "tensor([9.9995e-01, 5.0480e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5454729435381296e-09\n",
      "tensor([9.9998e-01, 2.1257e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.5105263968281406e-10\n",
      "tensor([1.0000e+00, 6.7511e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.836848695004281e-13\n",
      "tensor([0.5160, 0.4840], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.26625311374664307\n",
      "tensor([0.8822, 0.1178], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7783091068267822\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.4355399571286398e-06\n",
      "tensor([0.8202, 0.1798], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6727505326271057\n",
      "tensor([0.0151, 0.9849], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9699952006340027\n",
      "tensor([0.2018, 0.7982], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.040736109018325806\n",
      "tensor([9.9954e-01, 4.5593e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.0786734467037604e-07\n",
      "tensor([0.5380, 0.4620], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.28943461179733276\n",
      "tensor([0.9279, 0.0721], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005201035179197788\n",
      "tensor([0.0411, 0.9589], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0016879178583621979\n",
      "tensor([0.2338, 0.7662], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.05467916280031204\n",
      "tensor([9.9995e-01, 4.7761e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.2831256885069706e-09\n",
      "tensor([1.0000e+00, 7.6422e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.478085433191504e-13\n",
      "tensor([0.9896, 0.0104], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00010803241457324475\n",
      "tensor([0.7529, 0.2471], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0610533282160759\n",
      "tensor([0.9866, 0.0134], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00017927662702277303\n",
      "tensor([0.9828, 0.0172], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00029418201302178204\n",
      "tensor([0.0994, 0.9006], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.811037540435791\n",
      "tensor([1.0000e+00, 7.8647e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.092674506440624e-19\n",
      "tensor([0.9628, 0.0372], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9269200563430786\n",
      "tensor([9.9999e-01, 1.0668e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1318060377796257e-10\n",
      "tensor([0.7658, 0.2342], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.05486026778817177\n",
      "tensor([1.0000e+00, 1.3751e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.5801, 0.4199], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.17633262276649475\n",
      "tensor([0.7124, 0.2876], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.08270823955535889\n",
      "tensor([0.4887, 0.5113], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.23883649706840515\n",
      "tensor([9.9997e-01, 2.8730e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.253845384942338e-10\n",
      "tensor([0.4891, 0.5109], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.23919373750686646\n",
      "tensor([9.9999e-01, 5.0737e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999898076057434\n",
      "tensor([0.8927, 0.1073], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7969993352890015\n",
      "tensor([0.2614, 0.7386], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5456000566482544\n",
      "tensor([1.0000e+00, 2.8694e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.209523338909008e-12\n",
      "tensor([9.9987e-01, 1.2938e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6734507113369546e-08\n",
      "tensor([0.5286, 0.4714], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.22226493060588837\n",
      "tensor([9.9919e-01, 8.1470e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.637646947638132e-07\n",
      "tensor([0.5649, 0.4351], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.18932268023490906\n",
      "tensor([0.9065, 0.0935], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8216736912727356\n",
      "tensor([0.6886, 0.3114], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09694292396306992\n",
      "tensor([0.9783, 0.0217], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00046977304737083614\n",
      "tensor([0.3276, 0.6724], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.4521673917770386\n",
      "tensor([9.9964e-01, 3.6373e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.322896423516795e-07\n",
      "tensor([9.9989e-01, 1.1421e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997715950012207\n",
      "tensor([9.9989e-01, 1.0528e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997894763946533\n",
      "tensor([0.6134, 0.3866], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.37629711627960205\n",
      "tensor([0.1900, 0.8100], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6560267806053162\n",
      "tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8533594608306885\n",
      "tensor([9.9959e-01, 4.0632e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6509937950104359e-07\n",
      "tensor([0.9799, 0.0201], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0004056874313391745\n",
      "tensor([0.5348, 0.4652], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2860528230667114\n",
      "tensor([0.3379, 0.6621], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.11415360122919083\n",
      "tensor([0.9990, 0.0010], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0906770739893545e-06\n",
      "tensor([0.9688, 0.0312], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0009711695602163672\n",
      "tensor([0.9970, 0.0030], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.176852472592145e-06\n",
      "tensor([0.7076, 0.2924], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.500731885433197\n",
      "tensor([1.0000e+00, 1.1241e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999977946281433\n",
      "tensor([0.6602, 0.3398], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4358944296836853\n",
      "tensor([0.3669, 0.6331], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.4007672071456909\n",
      "tensor([0.4108, 0.5892], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.347190260887146\n",
      "tensor([9.9999e-01, 1.2714e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6216850085015722e-10\n",
      "tensor([0.6668, 0.3332], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11102348566055298\n",
      "tensor([0.9891, 0.0109], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00011837453348562121\n",
      "tensor([0.8323, 0.1677], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.028134852647781372\n",
      "tensor([0.1401, 0.8599], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.019638681784272194\n",
      "tensor([0.2064, 0.7936], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6298205852508545\n",
      "tensor([0.9916, 0.0084], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.023478974588215e-05\n",
      "tensor([0.9514, 0.0486], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.002359453123062849\n",
      "tensor([0.6438, 0.3562], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4145241677761078\n",
      "tensor([0.8093, 0.1907], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.03635789453983307\n",
      "tensor([9.9997e-01, 3.2872e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0815549567055882e-09\n",
      "tensor([9.9974e-01, 2.5516e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9994897246360779\n",
      "tensor([9.9968e-01, 3.2071e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0284308871177927e-07\n",
      "tensor([9.9945e-01, 5.5231e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.050696477657766e-07\n",
      "tensor([0.6566, 0.3434], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11794774234294891\n",
      "tensor([0.9259, 0.0741], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005489550065249205\n",
      "tensor([0.0933, 0.9067], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8220751881599426\n",
      "tensor([0.9311, 0.0689], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004745482467114925\n",
      "tensor([0.2389, 0.7611], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5793395638465881\n",
      "tensor([1.0000e+00, 1.4299e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.022274148859857e-20\n",
      "tensor([0.9860, 0.0140], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9721803069114685\n",
      "tensor([0.7894, 0.2106], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.04437117278575897\n",
      "tensor([9.9994e-01, 6.4729e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.1899674840806256e-09\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.9736015019589104e-05\n",
      "tensor([9.9999e-01, 6.1682e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.823655975176976e-11\n",
      "tensor([0.9977, 0.0023], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.225679615250556e-06\n",
      "tensor([0.0070, 0.9930], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9861016273498535\n",
      "tensor([0.6594, 0.3406], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.43477392196655273\n",
      "tensor([9.9999e-01, 9.4669e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.915574528645109e-11\n",
      "tensor([0.6302, 0.3698], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.39714959263801575\n",
      "tensor([0.5567, 0.4433], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.30995264649391174\n",
      "tensor([0.9985, 0.0015], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9970530271530151\n",
      "tensor([0.8711, 0.1289], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01661865785717964\n",
      "tensor([1.0000e+00, 9.5219e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.080839379060901e-13\n",
      "tensor([1.0000e+00, 2.4973e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.251769935072815e-12\n",
      "tensor([0.9407, 0.0593], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8849751353263855\n",
      "tensor([9.9999e-01, 6.7016e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.4738605181615654e-11\n",
      "tensor([9.9994e-01, 6.2175e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.868972697773643e-09\n",
      "tensor([0.6943, 0.3057], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4820549488067627\n",
      "tensor([0.0220, 0.9780], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9565631747245789\n",
      "tensor([0.0489, 0.9511], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0023929490707814693\n",
      "tensor([0.5636, 0.4364], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3176162838935852\n",
      "tensor([9.9959e-01, 4.0678e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9991865754127502\n",
      "tensor([0.3825, 0.6175], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3813225030899048\n",
      "tensor([0.9981, 0.0019], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.996279776096344\n",
      "tensor([0.0398, 0.9602], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.001585586927831173\n",
      "tensor([0.9971, 0.0029], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9941400289535522\n",
      "tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.492369847255759e-05\n",
      "tensor([0.9987, 0.0013], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8142845874535851e-06\n",
      "tensor([0.9352, 0.0648], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004196353256702423\n",
      "tensor([0.9682, 0.0318], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9374619126319885\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.818870077840984e-05\n",
      "tensor([0.7836, 0.2164], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6140490770339966\n",
      "tensor([0.9974, 0.0026], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.641178970312467e-06\n",
      "tensor([0.8883, 0.1117], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.012476736679673195\n",
      "tensor([1.0000e+00, 1.9253e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.672473783411512e-12\n",
      "tensor([0.7728, 0.2272], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0516345351934433\n",
      "tensor([0.2086, 0.7914], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6263867616653442\n",
      "tensor([0.9754, 0.0246], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0006035537226125598\n",
      "tensor([0.2251, 0.7749], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0506715327501297\n",
      "tensor([9.9995e-01, 5.3085e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999893844127655\n",
      "tensor([0.9584, 0.0416], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.001729276729747653\n",
      "tensor([0.0146, 0.9854], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.00021237204782664776\n",
      "tensor([0.6344, 0.3656], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4024578332901001\n",
      "tensor([9.9998e-01, 1.4982e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.2503157670605844e-10\n",
      "tensor([0.6706, 0.3294], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4497351348400116\n",
      "tensor([1.0000e+00, 1.0051e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.598465685461965e-13\n",
      "tensor([0.8454, 0.1546], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.714785099029541\n",
      "tensor([0.4454, 0.5546], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3075781464576721\n",
      "tensor([0.8694, 0.1306], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.017049459740519524\n",
      "tensor([0.9716, 0.0284], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9440222978591919\n",
      "tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.583989679813385\n",
      "tensor([1.0000e+00, 5.6420e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.5916323710940086e-19\n",
      "tensor([0.9515, 0.0485], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9052755236625671\n",
      "tensor([0.2248, 0.7752], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6009204387664795\n",
      "tensor([0.9730, 0.0270], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0007272367365658283\n",
      "tensor([0.0556, 0.9444], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8918994069099426\n",
      "tensor([0.9287, 0.0713], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005078034941107035\n",
      "tensor([0.9064, 0.0936], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.008752967230975628\n",
      "tensor([0.9848, 0.0152], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9697415232658386\n",
      "tensor([0.1750, 0.8250], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.030616112053394318\n",
      "tensor([0.9789, 0.0211], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9582868218421936\n",
      "tensor([0.0019, 0.9981], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9962863326072693\n",
      "tensor([0.4763, 0.5237], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2268374264240265\n",
      "tensor([1.0000e+00, 3.7277e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.334257953688328e-13\n",
      "tensor([9.9956e-01, 4.3595e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.9007894991318608e-07\n",
      "tensor([0.9376, 0.0624], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.879132866859436\n",
      "tensor([9.9980e-01, 2.0320e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.1289091257112887e-08\n",
      "tensor([0.7219, 0.2781], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5211769342422485\n",
      "tensor([0.9866, 0.0134], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9734537601470947\n",
      "tensor([9.9933e-01, 6.7329e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.5332217268878594e-07\n",
      "tensor([9.9995e-01, 4.7195e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999055862426758\n",
      "tensor([0.6721, 0.3279], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.45166850090026855\n",
      "tensor([9.9993e-01, 7.4022e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.479783737882826e-09\n",
      "tensor([0.9680, 0.0320], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0010265393648296595\n",
      "tensor([0.9979, 0.0021], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.402841113915201e-06\n",
      "tensor([0.7235, 0.2765], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5235058665275574\n",
      "tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004908392671495676\n",
      "tensor([1.0000e+00, 5.7428e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.42533347606061e-13\n",
      "tensor([0.9349, 0.0651], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004237886518239975\n",
      "tensor([1.0000e+00, 4.8767e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.383520811277684e-11\n",
      "tensor([0.3445, 0.6555], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.11868736147880554\n",
      "tensor([0.9829, 0.0171], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9661435484886169\n",
      "tensor([0.6019, 0.3981], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.36231887340545654\n",
      "tensor([9.9990e-01, 9.5045e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.030204140003661e-09\n",
      "tensor([0.5606, 0.4394], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3142705261707306\n",
      "tensor([0.9697, 0.0303], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9402927756309509\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1711274510162184e-06\n",
      "tensor([9.9997e-01, 3.3075e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999338984489441\n",
      "tensor([0.4099, 0.5901], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1680075228214264\n",
      "tensor([0.9680, 0.0320], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9369867444038391\n",
      "tensor([9.9950e-01, 5.0001e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.49987010647601e-07\n",
      "tensor([0.7724, 0.2276], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.05181696638464928\n",
      "tensor([9.9986e-01, 1.3957e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.9482818913729716e-08\n",
      "tensor([0.8313, 0.1687], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.028443222865462303\n",
      "tensor([0.9285, 0.0715], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005115913227200508\n",
      "tensor([0.1392, 0.8608], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.019365238025784492\n",
      "tensor([0.5432, 0.4568], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2950962781906128\n",
      "tensor([0.9919, 0.0081], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9838682413101196\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9978688359260559\n",
      "tensor([0.9887, 0.0113], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0001287461636820808\n",
      "tensor([1.0000e+00, 7.5322e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.836669665218309e-17\n",
      "tensor([9.9999e-01, 6.0785e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.6955036253338847e-11\n",
      "tensor([0.9823, 0.0177], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0003135151928290725\n",
      "tensor([0.4881, 0.5119], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.26206597685813904\n",
      "tensor([0.9990, 0.0010], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9979276061058044\n",
      "tensor([0.8850, 0.1150], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7832677960395813\n",
      "tensor([0.3788, 0.6212], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3858494460582733\n",
      "tensor([0.9889, 0.0111], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0001236504758708179\n",
      "tensor([0.3991, 0.6009], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1592869907617569\n",
      "tensor([0.7451, 0.2549], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.06498844176530838\n",
      "tensor([0.5799, 0.4201], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.17644569277763367\n",
      "tensor([1.0000e+00, 1.0967e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1768773889447859e-12\n",
      "tensor([0.9926, 0.0074], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.425832932814956e-05\n",
      "tensor([0.9740, 0.0260], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0006734346970915794\n",
      "tensor([0.9970, 0.0030], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.179869266517926e-06\n",
      "tensor([0.9951, 0.0049], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.381070953560993e-05\n",
      "tensor([0.3834, 0.6166], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.14700226485729218\n",
      "tensor([0.9161, 0.0839], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8392629623413086\n",
      "tensor([0.9982, 0.0018], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.1328258955909405e-06\n",
      "tensor([0.9842, 0.0158], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.000248293683398515\n",
      "tensor([9.9999e-01, 5.0119e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5093663258424215e-11\n",
      "tensor([0.8044, 0.1956], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6470880508422852\n",
      "tensor([0.9322, 0.0678], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8689264059066772\n",
      "tensor([0.9855, 0.0145], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0002115763636538759\n",
      "tensor([0.9973, 0.0027], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.198310413514264e-06\n",
      "tensor([0.4987, 0.5013], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2486778050661087\n",
      "tensor([0.8223, 0.1777], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6761741042137146\n",
      "tensor([1.0000e+00, 8.8436e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1015851520356466e-14\n",
      "tensor([0.9804, 0.0196], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0003824658633675426\n",
      "tensor([0.0722, 0.9278], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.005206810310482979\n",
      "tensor([0.7743, 0.2257], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5995936393737793\n",
      "tensor([9.9981e-01, 1.8535e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.4347419131108836e-08\n",
      "tensor([0.0054, 0.9946], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "2.8680158720817417e-05\n",
      "tensor([0.6200, 0.3800], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3843684792518616\n",
      "tensor([0.7322, 0.2678], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.07170490175485611\n",
      "tensor([0.1207, 0.8793], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.014557400718331337\n",
      "tensor([0.9502, 0.0498], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.002477423520758748\n",
      "tensor([0.9633, 0.0367], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0013471939601004124\n",
      "tensor([0.0434, 0.9566], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0018859837437048554\n",
      "tensor([1.0000e+00, 9.5160e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.075187433135734e-13\n",
      "tensor([0.5117, 0.4883], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.26179465651512146\n",
      "tensor([0.9482, 0.0518], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8989992737770081\n",
      "tensor([0.9885, 0.0115], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9771309494972229\n",
      "tensor([0.9976, 0.0024], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.748077455791645e-06\n",
      "tensor([0.9875, 0.0125], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00015738006914034486\n",
      "tensor([9.9989e-01, 1.1115e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.234858704179942e-08\n",
      "tensor([0.9169, 0.0831], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.006909478455781937\n",
      "tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.685947300866246e-05\n",
      "tensor([0.9979, 0.0021], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.4879852794110775e-06\n",
      "tensor([9.9993e-01, 6.8538e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.697982447510185e-09\n",
      "tensor([0.9510, 0.0490], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.904373824596405\n",
      "tensor([0.8440, 0.1560], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.024338258430361748\n",
      "tensor([0.4562, 0.5438], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2081506848335266\n",
      "tensor([0.8815, 0.1185], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7770007848739624\n",
      "tensor([0.9367, 0.0633], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8773869872093201\n",
      "tensor([0.9888, 0.0112], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0001264304737560451\n",
      "tensor([0.9521, 0.0479], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0022963196970522404\n",
      "tensor([0.9694, 0.0306], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9397048354148865\n",
      "tensor([0.9703, 0.0297], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0008849486475810409\n",
      "tensor([9.9964e-01, 3.5571e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2653237035920029e-07\n",
      "tensor([0.9518, 0.0482], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9058327078819275\n",
      "tensor([1.0000e+00, 6.5437e-17], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.1410088600602436e-33\n",
      "tensor([0.9911, 0.0089], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.947922858875245e-05\n",
      "tensor([0.9693, 0.0307], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.939560055732727\n",
      "tensor([9.9986e-01, 1.4127e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.995664078435766e-08\n",
      "tensor([0.7899, 0.2101], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6239403486251831\n",
      "tensor([1.0000e+00, 1.5000e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.3257875660098737e-12\n",
      "tensor([0.9828, 0.0172], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9659509062767029\n",
      "tensor([0.9396, 0.0604], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0036479465197771788\n",
      "tensor([1.0000e+00, 1.2003e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999997615814209\n",
      "tensor([9.9996e-01, 4.2849e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8337736884532774e-09\n",
      "tensor([0.9977, 0.0023], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.32065678271465e-06\n",
      "tensor([0.6267, 0.3733], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.39269042015075684\n",
      "tensor([0.6674, 0.3326], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.44539523124694824\n",
      "tensor([9.9952e-01, 4.7528e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990496635437012\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.5553550838376395e-06\n",
      "tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0869779884815216\n",
      "tensor([0.3397, 0.6603], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.11538036167621613\n",
      "tensor([0.5006, 0.4994], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2505912780761719\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9976428151130676\n",
      "tensor([1.0000e+00, 2.8015e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.017054034525906e-12\n",
      "tensor([0.7526, 0.2474], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5663734078407288\n",
      "tensor([0.9987, 0.0013], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9974727630615234\n",
      "tensor([1.0000e+00, 2.1296e-09], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.9939, 0.0061], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.6929741327185184e-05\n",
      "tensor([0.9973, 0.0027], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.0787091317470185e-06\n",
      "tensor([0.0162, 0.9838], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.00026297743897885084\n",
      "tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9925698041915894\n",
      "tensor([1.0000e+00, 1.7636e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999997019767761\n",
      "tensor([0.9979, 0.0021], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.4025036913808435e-06\n",
      "tensor([0.6357, 0.3643], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.1327047348022461\n",
      "tensor([9.9976e-01, 2.4318e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9995137453079224\n",
      "tensor([0.3052, 0.6948], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.48277097940444946\n",
      "tensor([9.9999e-01, 9.5933e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999808669090271\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9978535175323486\n",
      "tensor([0.4635, 0.5365], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.21486076712608337\n",
      "tensor([0.5759, 0.4241], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.33170086145401\n",
      "tensor([0.9310, 0.0690], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8666982054710388\n",
      "tensor([1.0000e+00, 1.9006e-09], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.8148, 0.1852], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.034299012273550034\n",
      "tensor([0.0382, 0.9618], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0014573454391211271\n",
      "tensor([1.0000e+00, 7.5702e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.423369002152678e-13\n",
      "tensor([1.0000e+00, 1.3607e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.257673066795477e-19\n",
      "tensor([0.1784, 0.8216], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6750082969665527\n",
      "tensor([0.9969, 0.0031], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.67515825323062e-06\n",
      "tensor([0.0172, 0.9828], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.965829074382782\n",
      "tensor([9.9995e-01, 5.4544e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.9779783083938582e-09\n",
      "tensor([0.2913, 0.7087], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5023210048675537\n",
      "tensor([0.9911, 0.0089], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.917075708974153e-05\n",
      "tensor([0.6817, 0.3183], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4647015333175659\n",
      "tensor([0.8765, 0.1235], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.015253911726176739\n",
      "tensor([1.0000e+00, 1.6619e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.9742, 0.0258], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0006653445889241993\n",
      "tensor([0.8945, 0.1055], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.011128753423690796\n",
      "tensor([0.9975, 0.0025], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9950667023658752\n",
      "tensor([0.7556, 0.2444], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5709120631217957\n",
      "tensor([9.9994e-01, 5.9602e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.5525749009224228e-09\n",
      "tensor([9.9981e-01, 1.8599e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9996280670166016\n",
      "tensor([9.9902e-01, 9.8146e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.632501587475417e-07\n",
      "tensor([0.4639, 0.5361], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.21520480513572693\n",
      "tensor([0.9983, 0.0017], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.896033947763499e-06\n",
      "tensor([1.0000e+00, 8.0635e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.732684071711348e-13\n",
      "tensor([1.0000e+00, 8.0348e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0333314065524846e-14\n",
      "tensor([0.9867, 0.0133], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00017662098980508745\n",
      "tensor([0.9403, 0.0597], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8841405510902405\n",
      "tensor([0.9291, 0.0709], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8633041381835938\n",
      "tensor([0.8674, 0.1326], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.017581243067979813\n",
      "tensor([0.4770, 0.5230], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.22755473852157593\n",
      "tensor([0.8708, 0.1292], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01669832319021225\n",
      "tensor([0.4009, 0.5991], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3589221239089966\n",
      "tensor([0.7056, 0.2944], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4978017508983612\n",
      "tensor([0.9490, 0.0510], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.002602029126137495\n",
      "tensor([0.9885, 0.0115], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00013227001181803644\n",
      "tensor([0.1333, 0.8667], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.7512254118919373\n",
      "tensor([0.8381, 0.1619], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.026216203346848488\n",
      "tensor([0.5961, 0.4039], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.35536569356918335\n",
      "tensor([0.5313, 0.4687], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.21966196596622467\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2019619362035883e-06\n",
      "tensor([0.9578, 0.0422], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0017771385610103607\n",
      "tensor([0.9819, 0.0181], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00032852613367140293\n",
      "tensor([0.8653, 0.1347], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7488259077072144\n",
      "tensor([1.0000e+00, 2.5396e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.2247894674321207e-20\n",
      "tensor([0.5666, 0.4334], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3210561275482178\n",
      "tensor([9.9997e-01, 3.0792e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.470351169937885e-10\n",
      "tensor([9.9996e-01, 3.9171e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999216198921204\n",
      "tensor([0.0797, 0.9203], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8468924164772034\n",
      "tensor([0.8415, 0.1585], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.708147406578064\n",
      "tensor([0.9700, 0.0300], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0008982548024505377\n",
      "tensor([9.9927e-01, 7.3059e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.337515176506713e-07\n",
      "tensor([1.0000e+00, 7.5293e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.392472492843359e-13\n",
      "tensor([0.5657, 0.4343], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.1886473447084427\n",
      "tensor([1.0000e+00, 1.3011e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.5569304133151822e-14\n",
      "tensor([0.7946, 0.2054], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.04220791906118393\n",
      "tensor([1.0000e+00, 1.7601e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999964237213135\n",
      "tensor([0.1808, 0.8192], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6710100173950195\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8901389466918772e-06\n",
      "tensor([0.3864, 0.6136], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.14930450916290283\n",
      "tensor([0.9694, 0.0306], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0009372445056214929\n",
      "tensor([0.2927, 0.7073], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08568032085895538\n",
      "tensor([0.9624, 0.0376], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.926190197467804\n",
      "tensor([0.2095, 0.7905], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6249105930328369\n",
      "tensor([0.8977, 0.1023], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.010470109060406685\n",
      "tensor([0.2887, 0.7113], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08335763216018677\n",
      "tensor([0.5666, 0.4334], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.32108360528945923\n",
      "tensor([0.3928, 0.6072], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.15428569912910461\n",
      "tensor([0.0958, 0.9042], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8176587820053101\n",
      "tensor([9.9996e-01, 4.3059e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999139308929443\n",
      "tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.9033701139269397e-05\n",
      "tensor([0.9828, 0.0172], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9658856391906738\n",
      "tensor([6.6353e-04, 9.9934e-01], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4030488766111375e-07\n",
      "tensor([9.9924e-01, 7.5553e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.998489499092102\n",
      "tensor([9.9998e-01, 2.0346e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.147493737338692e-10\n",
      "tensor([0.9905, 0.0095], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.955600787885487e-05\n",
      "tensor([0.8348, 0.1652], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6969627737998962\n",
      "tensor([9.9959e-01, 4.1394e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.7135135976786842e-07\n",
      "tensor([0.1988, 0.8012], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.03951359540224075\n",
      "tensor([0.9978, 0.0022], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.9622713049757294e-06\n",
      "tensor([9.9993e-01, 6.6834e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.46961134770163e-09\n",
      "tensor([1.0000e+00, 7.8703e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.578729531622751e-13\n",
      "tensor([9.9999e-01, 8.5551e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.342901287010761e-11\n",
      "tensor([0.6323, 0.3677], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.13521644473075867\n",
      "tensor([0.7891, 0.2109], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.04446162283420563\n",
      "tensor([1.0000e+00, 2.0604e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.176149009937902e-12\n",
      "tensor([0.9949, 0.0051], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5968780391849577e-05\n",
      "tensor([0.9976, 0.0024], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.533326202566968e-06\n",
      "tensor([0.9748, 0.0252], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9501426219940186\n",
      "tensor([0.1080, 0.8920], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.011657032184302807\n",
      "tensor([1.0000e+00, 1.3295e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.5943340330132165e-14\n",
      "tensor([0.2407, 0.7593], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5764945149421692\n",
      "tensor([0.8921, 0.1079], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01163545809686184\n",
      "tensor([1.0000e+00, 7.4413e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.326610463471382e-13\n",
      "tensor([0.0087, 0.9913], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.982745349407196\n",
      "tensor([0.3511, 0.6489], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.12330301851034164\n",
      "tensor([0.6231, 0.3769], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.14205560088157654\n",
      "tensor([0.9443, 0.0557], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0030974573455750942\n",
      "tensor([0.9770, 0.0230], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0005271854461170733\n",
      "tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.692986062262207e-05\n",
      "tensor([9.9998e-01, 1.7300e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.9904412279790904e-10\n",
      "tensor([0.9642, 0.0358], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9296902418136597\n",
      "tensor([0.9528, 0.0472], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.002223301911726594\n",
      "tensor([0.9639, 0.0361], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0013017833698540926\n",
      "tensor([0.9756, 0.0244], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0005973831284791231\n",
      "tensor([0.1715, 0.8285], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6864747405052185\n",
      "tensor([0.8826, 0.1174], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.013783891685307026\n",
      "tensor([0.6838, 0.3162], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09999728202819824\n",
      "tensor([0.5482, 0.4518], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.30047541856765747\n",
      "tensor([0.9929, 0.0071], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.060368130216375e-05\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2662154631470912e-06\n",
      "tensor([0.5012, 0.4988], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2512076497077942\n",
      "tensor([0.3712, 0.6288], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1378028243780136\n",
      "tensor([9.9999e-01, 9.2281e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.470698448226344e-11\n",
      "tensor([9.9985e-01, 1.5276e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.3345261723761723e-08\n",
      "tensor([0.1044, 0.8956], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8020338416099548\n",
      "tensor([0.2616, 0.7384], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.06841623038053513\n",
      "tensor([9.9998e-01, 2.2536e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999549388885498\n",
      "tensor([0.1620, 0.8380], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.026228047907352448\n",
      "tensor([0.7881, 0.2119], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6210922002792358\n",
      "tensor([9.9995e-01, 4.7841e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.286945521845496e-09\n",
      "tensor([1.0000e+00, 2.0851e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999995827674866\n",
      "tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9891479015350342\n",
      "tensor([0.9099, 0.0901], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8279216289520264\n",
      "tensor([0.7019, 0.2981], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.492630273103714\n",
      "tensor([9.9996e-01, 3.8392e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.473691391140619e-09\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8753480617306195e-05\n",
      "tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.484291672706604\n",
      "tensor([0.9324, 0.0676], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004572327248752117\n",
      "tensor([0.8386, 0.1614], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.026042763143777847\n",
      "tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.780777766834944e-05\n",
      "tensor([0.3259, 0.6741], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.45443034172058105\n",
      "tensor([0.0534, 0.9466], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8960771560668945\n",
      "tensor([0.9899, 0.0101], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.979968249797821\n",
      "tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.016714245080947876\n",
      "tensor([0.5450, 0.4550], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.20703253149986267\n",
      "tensor([0.8934, 0.1066], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.011365601792931557\n",
      "tensor([0.0188, 0.9812], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0003519540186971426\n",
      "tensor([0.3761, 0.6239], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3892732858657837\n",
      "tensor([9.9996e-01, 4.1681e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.739074440010313e-09\n",
      "tensor([1.0000e+00, 3.2384e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999999403953552\n",
      "tensor([0.9649, 0.0351], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00122916791588068\n",
      "tensor([9.9997e-01, 2.6970e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.266119927962222e-10\n",
      "tensor([0.0679, 0.9321], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0046074045822024345\n",
      "tensor([1.0000e+00, 6.1720e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.681019248094608e-13\n",
      "tensor([0.4126, 0.5874], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1702479124069214\n",
      "tensor([0.5468, 0.4532], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.29899296164512634\n",
      "tensor([0.9982, 0.0018], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.996430516242981\n",
      "tensor([0.9931, 0.0069], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.829453973798081e-05\n",
      "tensor([9.9986e-01, 1.3718e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997255802154541\n",
      "tensor([0.8113, 0.1887], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.035606928169727325\n",
      "tensor([9.9997e-01, 2.9706e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.817781504966149e-10\n",
      "tensor([0.7595, 0.2405], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5768768787384033\n",
      "tensor([0.1825, 0.8175], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6682502627372742\n",
      "tensor([0.9951, 0.0049], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9902663826942444\n",
      "tensor([0.7588, 0.2412], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5757165551185608\n",
      "tensor([0.9671, 0.0329], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0010856334120035172\n",
      "tensor([1.0000e+00, 2.0901e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.18436086578231e-18\n",
      "tensor([9.9999e-01, 5.4164e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999892115592957\n",
      "tensor([0.0824, 0.9176], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.006792708300054073\n",
      "tensor([0.9949, 0.0051], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.56104685831815e-05\n",
      "tensor([1.0000e+00, 2.5005e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.96837303971226e-14\n",
      "tensor([1.0000e+00, 4.6890e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.180088401471103e-11\n",
      "tensor([9.9937e-01, 6.3373e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.0156595559892594e-07\n",
      "tensor([0.8669, 0.1331], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01772872731089592\n",
      "tensor([0.6414, 0.3586], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4113974869251251\n",
      "tensor([8.1540e-05, 9.9992e-01], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "6.648665173969448e-09\n",
      "tensor([0.9884, 0.0116], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00013445268268696964\n",
      "tensor([9.9999e-01, 6.9018e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999861717224121\n",
      "tensor([0.0103, 0.9897], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9794531464576721\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.994593276322121e-06\n",
      "tensor([0.9939, 0.0061], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.697093779919669e-05\n",
      "tensor([0.9990, 0.0010], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9979721307754517\n",
      "tensor([9.9921e-01, 7.8590e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.17673208580527e-07\n",
      "tensor([0.9982, 0.0018], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.2904411000345135e-06\n",
      "tensor([0.9983, 0.0017], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.031898359040497e-06\n",
      "tensor([0.9853, 0.0147], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0002165521727874875\n",
      "tensor([1.0000e+00, 1.0840e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1630337535054047e-12\n",
      "tensor([0.8259, 0.1741], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6821893453598022\n",
      "tensor([0.9816, 0.0184], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0003401025605853647\n",
      "tensor([0.9282, 0.0718], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8615263104438782\n",
      "tensor([0.2489, 0.7511], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0619686022400856\n",
      "tensor([0.9014, 0.0986], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.009719448164105415\n",
      "tensor([0.9229, 0.0771], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005939883179962635\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2435298231139313e-06\n",
      "tensor([0.8051, 0.1949], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.037972256541252136\n",
      "tensor([0.9967, 0.0033], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9933918118476868\n",
      "tensor([1.0000e+00, 6.6648e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999986290931702\n",
      "tensor([0.9056, 0.0944], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.008912485092878342\n",
      "tensor([0.8681, 0.1319], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7535138130187988\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3070138038528967e-06\n",
      "tensor([0.6617, 0.3383], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11444780230522156\n",
      "tensor([1.0000e+00, 1.0929e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.971761610899619e-17\n",
      "tensor([0.4513, 0.5487], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.20365163683891296\n",
      "tensor([1.0000e+00, 3.3761e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1269752492326646e-11\n",
      "tensor([0.9899, 0.0101], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9798829555511475\n",
      "tensor([0.7978, 0.2022], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.636493980884552\n",
      "tensor([0.2839, 0.7161], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08058849722146988\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.9856117887684377e-06\n",
      "tensor([9.9987e-01, 1.3395e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.7948302399872773e-08\n",
      "tensor([0.8552, 0.1448], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.02096889354288578\n",
      "tensor([0.5302, 0.4698], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2811446189880371\n",
      "tensor([0.8734, 0.1266], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7627825736999512\n",
      "tensor([0.9755, 0.0245], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9515072703361511\n",
      "tensor([0.9985, 0.0015], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.354689286221401e-06\n",
      "tensor([9.9903e-01, 9.7250e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.457693295189529e-07\n",
      "tensor([0.4063, 0.5937], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.16509756445884705\n",
      "tensor([0.8917, 0.1083], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7950920462608337\n",
      "tensor([9.9998e-01, 1.7921e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.2044919495710644e-10\n",
      "tensor([0.0040, 0.9960], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.624838296265807e-05\n",
      "tensor([0.9715, 0.0285], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0008140419377014041\n",
      "tensor([0.5106, 0.4894], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.26069772243499756\n",
      "tensor([0.9761, 0.0239], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0005722116329707205\n",
      "tensor([0.9489, 0.0511], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0026148417964577675\n",
      "tensor([9.9987e-01, 1.2830e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997434616088867\n",
      "tensor([0.0267, 0.9733], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9473753571510315\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.997873067855835\n",
      "tensor([9.9916e-01, 8.3611e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.990998144829064e-07\n",
      "tensor([0.6896, 0.3104], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09632128477096558\n",
      "tensor([9.9964e-01, 3.5904e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2891777600998466e-07\n",
      "tensor([1.0000e+00, 6.6509e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.317159131889963e-15\n",
      "tensor([0.9932, 0.0068], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.61250965599902e-05\n",
      "tensor([0.9972, 0.0028], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.868451575632207e-06\n",
      "tensor([9.9976e-01, 2.4474e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999510645866394\n",
      "tensor([0.9384, 0.0616], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0037907951045781374\n",
      "tensor([0.8579, 0.1421], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.02019675076007843\n",
      "tensor([9.9954e-01, 4.5689e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.0870976413789322e-07\n",
      "tensor([9.9997e-01, 2.6179e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.865786827958686e-10\n",
      "tensor([1.0000e+00, 3.1985e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0295106780966456e-11\n",
      "tensor([0.9869, 0.0131], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00017209240468218923\n",
      "tensor([1.0000e+00, 1.2760e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.140524322823728e-21\n",
      "tensor([0.5429, 0.4571], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.29469871520996094\n",
      "tensor([0.9947, 0.0053], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.7971927920589224e-05\n",
      "tensor([0.2755, 0.7245], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5249063372612\n",
      "tensor([0.0605, 0.9395], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.00365904881618917\n",
      "tensor([0.9873, 0.0127], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9748296141624451\n",
      "tensor([9.9928e-01, 7.2201e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.212816631683381e-07\n",
      "tensor([0.9958, 0.0042], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.7775804735720158e-05\n",
      "tensor([0.2807, 0.7193], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.07881063967943192\n",
      "tensor([0.9278, 0.0722], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005216611083596945\n",
      "tensor([0.9643, 0.0357], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0012724633561447263\n",
      "tensor([9.9949e-01, 5.0655e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9989871978759766\n",
      "tensor([9.9969e-01, 3.0712e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9993858933448792\n",
      "tensor([0.1767, 0.8233], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.031209778040647507\n",
      "tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6880087059689686e-05\n",
      "tensor([0.6911, 0.3089], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09540223330259323\n",
      "tensor([9.9996e-01, 4.3835e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999123215675354\n",
      "tensor([9.9999e-01, 1.0305e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0565159858089146e-10\n",
      "tensor([0.2838, 0.7162], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08056505024433136\n",
      "tensor([1.0000e+00, 3.3541e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.119562602347468e-11\n",
      "tensor([0.5388, 0.4612], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2902775704860687\n",
      "tensor([0.4408, 0.5592], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.19429033994674683\n",
      "tensor([0.9466, 0.0534], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8961306214332581\n",
      "tensor([9.9998e-01, 2.1211e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.500894656978005e-10\n",
      "tensor([9.9909e-01, 9.1101e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.299265346067841e-07\n",
      "tensor([0.9977, 0.0023], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.324674020812381e-06\n",
      "tensor([9.9983e-01, 1.7365e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9996528029441833\n",
      "tensor([0.6107, 0.3893], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.15152065455913544\n",
      "tensor([0.5765, 0.4235], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3322950303554535\n",
      "tensor([0.9831, 0.0169], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0002850486198440194\n",
      "tensor([9.9998e-01, 1.5942e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5466215247682555e-10\n",
      "tensor([0.3157, 0.6843], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.09963764995336533\n",
      "tensor([0.5589, 0.4411], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3123779892921448\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8604510842124e-05\n",
      "tensor([0.3715, 0.6285], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.13803046941757202\n",
      "tensor([0.9379, 0.0621], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.879632830619812\n",
      "tensor([6.2413e-06, 9.9999e-01], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "3.868987769051202e-11\n",
      "tensor([1.0000e+00, 1.2160e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.393655160619614e-19\n",
      "tensor([0.5888, 0.4112], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.16912606358528137\n",
      "tensor([0.6407, 0.3593], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4105372428894043\n",
      "tensor([9.9908e-01, 9.2229e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.506449376000091e-07\n",
      "tensor([0.9658, 0.0342], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9328342080116272\n",
      "tensor([9.9933e-01, 6.6928e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.4790959918827866e-07\n",
      "tensor([0.6935, 0.3065], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4808990955352783\n",
      "tensor([0.9867, 0.0133], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9735237956047058\n",
      "tensor([0.9818, 0.0182], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9638454914093018\n",
      "tensor([0.6052, 0.3948], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.15589983761310577\n",
      "tensor([9.9932e-01, 6.8321e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.6675938847329235e-07\n",
      "tensor([1.0000e+00, 3.5851e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2821212461936599e-13\n",
      "tensor([0.7351, 0.2649], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.07018876075744629\n",
      "tensor([0.8953, 0.1047], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.010953454300761223\n",
      "tensor([0.5342, 0.4658], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.216986283659935\n",
      "tensor([9.9984e-01, 1.6414e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9996716976165771\n",
      "tensor([0.9990, 0.0010], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.069175596057903e-06\n",
      "tensor([0.8429, 0.1571], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7105430960655212\n",
      "tensor([0.5405, 0.4595], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.2111547589302063\n",
      "tensor([9.9999e-01, 9.2646e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.614602087231304e-11\n",
      "tensor([0.9535, 0.0465], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0021590436808764935\n",
      "tensor([0.3257, 0.6743], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.45466217398643494\n",
      "tensor([0.9165, 0.0835], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8400391936302185\n",
      "tensor([0.8491, 0.1509], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.022779494524002075\n",
      "tensor([9.9999e-01, 1.0864e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.178548647562394e-10\n",
      "tensor([0.7642, 0.2358], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5840002298355103\n",
      "tensor([0.9889, 0.0111], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9780036211013794\n",
      "tensor([0.8087, 0.1913], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.03660373389720917\n",
      "tensor([0.9869, 0.0131], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9740203022956848\n",
      "tensor([0.9981, 0.0019], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.695964778671623e-06\n",
      "tensor([9.9996e-01, 3.7497e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999249577522278\n",
      "tensor([0.9966, 0.0034], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9932321906089783\n",
      "tensor([0.9960, 0.0040], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.5839577827136964e-05\n",
      "tensor([0.9931, 0.0069], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9861510396003723\n",
      "tensor([0.9980, 0.0020], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.883681529259775e-06\n",
      "tensor([0.5117, 0.4883], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.26184311509132385\n",
      "tensor([0.9359, 0.0641], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004108068533241749\n",
      "tensor([0.9971, 0.0029], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.539257578377146e-06\n",
      "tensor([0.9351, 0.0649], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004206234123557806\n",
      "tensor([0.2653, 0.7347], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5398404002189636\n",
      "tensor([9.9990e-01, 1.0087e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0173234699095701e-08\n",
      "tensor([0.9972, 0.0028], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.96113999967929e-06\n",
      "tensor([0.2105, 0.7895], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.623341977596283\n",
      "tensor([0.9975, 0.0025], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.0991205828031525e-06\n",
      "tensor([0.9870, 0.0130], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00016947041149251163\n",
      "tensor([0.6469, 0.3531], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.41844385862350464\n",
      "tensor([0.7028, 0.2972], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.49394020438194275\n",
      "tensor([1.0000e+00, 5.4796e-09], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.6142, 0.3858], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.37729668617248535\n",
      "tensor([9.9999e-01, 8.6932e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.56504719978679e-11\n",
      "tensor([0.6003, 0.3997], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3603692054748535\n",
      "tensor([0.9702, 0.0298], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0008882633992470801\n",
      "tensor([1.0000e+00, 4.8612e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.3760056422350573e-11\n",
      "tensor([9.9998e-01, 1.5995e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5549842797012445e-10\n",
      "tensor([0.1723, 0.8277], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6850668787956238\n",
      "tensor([0.9695, 0.0305], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0009328923188149929\n",
      "tensor([0.3125, 0.6875], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.09768529236316681\n",
      "tensor([0.9893, 0.0107], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00011413121683290228\n",
      "tensor([0.6436, 0.3564], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4142436683177948\n",
      "tensor([0.9316, 0.0684], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004680020269006491\n",
      "tensor([0.9817, 0.0183], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00033358170185238123\n",
      "tensor([0.1573, 0.8427], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.02473084256052971\n",
      "tensor([0.9929, 0.0071], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9857896566390991\n",
      "tensor([0.9599, 0.0401], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9214764833450317\n",
      "tensor([1.0000e+00, 7.7219e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.9813636548427186e-19\n",
      "tensor([0.1117, 0.8883], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.012480389326810837\n",
      "tensor([9.9990e-01, 9.5187e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.066436490456908e-09\n",
      "tensor([0.9820, 0.0180], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0003236238844692707\n",
      "tensor([0.9949, 0.0051], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.6293737391824834e-05\n",
      "tensor([0.8947, 0.1053], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.011079425923526287\n",
      "tensor([9.9958e-01, 4.1674e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.736548824737838e-07\n",
      "tensor([0.9155, 0.0845], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.007136966101825237\n",
      "tensor([0.9971, 0.0029], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.155059731507208e-06\n",
      "tensor([9.9979e-01, 2.0802e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.326073366200944e-08\n",
      "tensor([9.9983e-01, 1.6900e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.8566898180315548e-08\n",
      "tensor([0.8942, 0.1058], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011191755533218384\n",
      "tensor([0.9977, 0.0023], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.126244104758371e-06\n",
      "tensor([0.1414, 0.8586], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.019996685907244682\n",
      "tensor([0.9542, 0.0458], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.002096038544550538\n",
      "tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.49176138639450073\n",
      "tensor([0.2856, 0.7144], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.510388970375061\n",
      "tensor([0.9985, 0.0015], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.2024971713108243e-06\n",
      "tensor([0.6843, 0.3157], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4682890772819519\n",
      "tensor([0.9095, 0.0905], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.82720947265625\n",
      "tensor([0.9824, 0.0176], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9651271104812622\n",
      "tensor([0.9828, 0.0172], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9659022092819214\n",
      "tensor([1.0000e+00, 6.4191e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999998211860657\n",
      "tensor([0.0029, 0.9971], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9942512512207031\n",
      "tensor([0.8729, 0.1271], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.016163839027285576\n",
      "tensor([0.2462, 0.7538], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.060590218752622604\n",
      "tensor([9.9997e-01, 3.2362e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999353289604187\n",
      "tensor([0.9976, 0.0024], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.995116651058197\n",
      "tensor([0.9905, 0.0095], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.94403929123655e-05\n",
      "tensor([0.9909, 0.0091], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.333205187227577e-05\n",
      "tensor([0.9125, 0.0875], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.007647654041647911\n",
      "tensor([1.0000e+00, 4.2261e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.929969783788181e-16\n",
      "tensor([0.4384, 0.5616], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.19218164682388306\n",
      "tensor([0.2981, 0.7019], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08889080584049225\n",
      "tensor([9.9997e-01, 2.9258e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.545088525657718e-10\n",
      "tensor([0.9964, 0.0036], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9928592443466187\n",
      "tensor([9.9997e-01, 3.3151e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.098622970374663e-09\n",
      "tensor([0.9929, 0.0071], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9857895374298096\n",
      "tensor([0.0486, 0.9514], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9051507115364075\n",
      "tensor([0.7672, 0.2328], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5885214805603027\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3354135717236204e-06\n",
      "tensor([0.4799, 0.5201], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2302853763103485\n",
      "tensor([0.3904, 0.6096], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.15239137411117554\n",
      "tensor([9.9935e-01, 6.5116e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.2402280087117106e-07\n",
      "tensor([1.0000e+00, 4.0344e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.635186777648734e-11\n",
      "tensor([9.9997e-01, 2.9243e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.540878004836827e-10\n",
      "tensor([1.0000e+00, 2.0892e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.024569627552766e-14\n",
      "tensor([9.9916e-01, 8.4217e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.092892815308005e-07\n",
      "tensor([0.9448, 0.0552], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0030466606840491295\n",
      "tensor([0.1841, 0.8159], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.665692150592804\n",
      "tensor([9.9998e-01, 1.9707e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.8763428578114656e-10\n",
      "tensor([0.9901, 0.0099], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9802907109260559\n",
      "tensor([9.9995e-01, 4.7759e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.2830233259441e-09\n",
      "tensor([0.9451, 0.0549], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0030089090578258038\n",
      "tensor([0.9870, 0.0130], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9741498231887817\n",
      "tensor([0.6564, 0.3436], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11806802451610565\n",
      "tensor([0.8321, 0.1679], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.028201524168252945\n",
      "tensor([0.6937, 0.3063], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4811633229255676\n",
      "tensor([9.9998e-01, 2.0362e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.150705890104689e-10\n",
      "tensor([0.5572, 0.4428], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.310496985912323\n",
      "tensor([9.9995e-01, 5.4022e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999891996383667\n",
      "tensor([1.0000e+00, 1.9115e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999961853027344\n",
      "tensor([0.2197, 0.7803], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.608842134475708\n",
      "tensor([0.9267, 0.0733], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0053680408746004105\n",
      "tensor([1.0000e+00, 1.5386e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1835855158589212e-20\n",
      "tensor([0.9880, 0.0120], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00014509483298752457\n",
      "tensor([0.9943, 0.0057], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.2165611628443e-05\n",
      "tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2172800779808313e-05\n",
      "tensor([0.9597, 0.0403], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9210668802261353\n",
      "tensor([0.4812, 0.5188], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.2691393196582794\n",
      "tensor([0.3055, 0.6945], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.4823020100593567\n",
      "tensor([0.7982, 0.2018], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0407252311706543\n",
      "tensor([9.9983e-01, 1.7246e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.9749234187192997e-08\n",
      "tensor([0.9735, 0.0265], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9476680755615234\n",
      "tensor([9.9969e-01, 3.1307e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9993740320205688\n",
      "tensor([0.6761, 0.3239], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4571104943752289\n",
      "tensor([9.9925e-01, 7.4622e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.568214191953302e-07\n",
      "tensor([0.9295, 0.0705], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8639847040176392\n",
      "tensor([9.9999e-01, 5.0363e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.521619371642636e-11\n",
      "tensor([9.9946e-01, 5.3683e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.8820232955695246e-07\n",
      "tensor([0.2642, 0.7358], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.06979694962501526\n",
      "tensor([1.0000e+00, 7.9170e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999983906745911\n",
      "tensor([0.0317, 0.9683], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9376392960548401\n",
      "tensor([1.0000e+00, 2.1002e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.5076542325162006e-12\n",
      "tensor([0.8647, 0.1353], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.018293730914592743\n",
      "tensor([0.8972, 0.1028], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8050392866134644\n",
      "tensor([0.3713, 0.6287], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.13785427808761597\n",
      "tensor([0.6957, 0.3043], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4839733839035034\n",
      "tensor([0.4000, 0.6000], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3600400686264038\n",
      "tensor([0.8290, 0.1710], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.029235363006591797\n",
      "tensor([9.9966e-01, 3.3917e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.150284418827141e-07\n",
      "tensor([0.7013, 0.2987], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.08924395591020584\n",
      "tensor([9.9983e-01, 1.7066e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.913224861345043e-08\n",
      "tensor([0.9562, 0.0438], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0019208920421078801\n",
      "tensor([0.9261, 0.0739], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8576359748840332\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8872560758609325e-06\n",
      "tensor([0.9976, 0.0024], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.783870619779918e-06\n",
      "tensor([0.9077, 0.0923], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.008525323122739792\n",
      "tensor([0.5032, 0.4968], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.25325626134872437\n",
      "tensor([0.9923, 0.0077], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.93107397435233e-05\n",
      "tensor([9.9977e-01, 2.3411e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.479678577557934e-08\n",
      "tensor([9.9997e-01, 2.7364e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999452233314514\n",
      "tensor([1.0000e+00, 2.3228e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.6976112687394506e-20\n",
      "tensor([9.9996e-01, 4.1648e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.732740506632524e-09\n",
      "tensor([0.5162, 0.4838], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.23409046232700348\n",
      "tensor([0.9938, 0.0062], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.8827711250633e-05\n",
      "tensor([0.8470, 0.1530], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.02341008558869362\n",
      "tensor([0.8869, 0.1131], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.012789216823875904\n",
      "tensor([0.7391, 0.2609], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.06809243559837341\n",
      "tensor([1.0000e+00, 3.5788e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.40383695541208e-16\n",
      "tensor([0.7857, 0.2143], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6173326969146729\n",
      "tensor([0.4802, 0.5198], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.27017727494239807\n",
      "tensor([9.9989e-01, 1.1460e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3129083598073521e-08\n",
      "tensor([0.1275, 0.8725], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.7612007260322571\n",
      "tensor([1.0000e+00, 3.3330e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1124995889788547e-11\n",
      "tensor([1.0000e+00, 1.7642e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.556236163935789e-16\n",
      "tensor([0.1790, 0.8210], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6740261316299438\n",
      "tensor([0.6347, 0.3653], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4028577506542206\n",
      "tensor([0.9860, 0.0140], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0001950631703948602\n",
      "tensor([0.3191, 0.6809], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.10180479288101196\n",
      "tensor([0.5872, 0.4128], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.34478890895843506\n",
      "tensor([0.4015, 0.5985], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1612078845500946\n",
      "tensor([0.9671, 0.0329], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0010804752819240093\n",
      "tensor([0.6860, 0.3140], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09862592816352844\n",
      "tensor([9.9992e-01, 7.7318e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.98186122857669e-09\n",
      "tensor([0.4605, 0.5395], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.21210069954395294\n",
      "tensor([1.0000e+00, 7.6109e-11], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.8962885004266805e-21\n",
      "tensor([0.0355, 0.9645], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9301764369010925\n",
      "tensor([0.8021, 0.1979], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.643296480178833\n",
      "tensor([0.0128, 0.9872], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9746552109718323\n",
      "tensor([0.0022, 0.9978], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "4.6826835387037136e-06\n",
      "tensor([0.5559, 0.4441], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.30897945165634155\n",
      "tensor([0.9975, 0.0025], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9949729442596436\n",
      "tensor([0.9736, 0.0264], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0006971184629946947\n",
      "tensor([0.9981, 0.0019], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9961836338043213\n",
      "tensor([9.9974e-01, 2.5593e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9994882345199585\n",
      "tensor([9.9976e-01, 2.3804e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9995239973068237\n",
      "tensor([1.0000e+00, 2.5547e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.3966167432316645e-12\n",
      "tensor([0.9369, 0.0631], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.003978928551077843\n",
      "tensor([0.7352, 0.2648], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.07010787725448608\n",
      "tensor([0.9977, 0.0023], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9953155517578125\n",
      "tensor([0.8707, 0.1293], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.016723530367016792\n",
      "tensor([0.4774, 0.5226], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.22791971266269684\n",
      "tensor([0.7584, 0.2416], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.058384209871292114\n",
      "tensor([0.9814, 0.0186], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00034596299519762397\n",
      "tensor([1.0000e+00, 2.7594e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.807206716345248e-18\n",
      "tensor([0.7228, 0.2772], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.07683075219392776\n",
      "tensor([0.8485, 0.1515], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.022964652627706528\n",
      "tensor([0.6578, 0.3422], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11712554097175598\n",
      "tensor([0.6456, 0.3544], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4167851209640503\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9977607727050781\n",
      "tensor([0.9669, 0.0331], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0010938961058855057\n",
      "tensor([0.6687, 0.3313], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.44710344076156616\n",
      "tensor([0.2852, 0.7148], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0813586488366127\n",
      "tensor([0.9964, 0.0036], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2855321983806789e-05\n",
      "tensor([0.6628, 0.3372], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.43932589888572693\n",
      "tensor([9.9979e-01, 2.1075e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.440608591949058e-08\n",
      "tensor([0.7766, 0.2234], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6031374931335449\n",
      "tensor([0.9777, 0.0223], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.000495170068461448\n",
      "tensor([0.9539, 0.0461], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0021273032762110233\n",
      "tensor([0.5892, 0.4108], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.34715887904167175\n",
      "tensor([0.6128, 0.3872], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3755815923213959\n",
      "tensor([9.9999e-01, 7.1652e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.1249667704089674e-11\n",
      "tensor([0.8644, 0.1356], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7472013831138611\n",
      "tensor([9.9999e-01, 6.6137e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.3364457857908434e-11\n",
      "tensor([0.9673, 0.0327], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0010671793716028333\n",
      "tensor([0.8914, 0.1086], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.011799291707575321\n",
      "tensor([0.9735, 0.0265], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0007014468428678811\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8299242583452724e-06\n",
      "tensor([9.9976e-01, 2.4008e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999519944190979\n",
      "tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9921426177024841\n",
      "tensor([0.7051, 0.2949], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4971763491630554\n",
      "tensor([9.9996e-01, 4.4817e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.008835320310709e-09\n",
      "tensor([0.4110, 0.5890], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.16894280910491943\n",
      "tensor([9.9998e-01, 2.0551e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.213782933693011e-10\n",
      "tensor([0.9980, 0.0020], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.995853148808237e-06\n",
      "tensor([0.1065, 0.8935], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.011352524161338806\n",
      "tensor([9.9995e-01, 5.1119e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.6142492615122137e-09\n",
      "tensor([0.8307, 0.1693], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6900933980941772\n",
      "tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.877307653427124\n",
      "tensor([0.9819, 0.0181], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00032839429331943393\n",
      "tensor([0.0430, 0.9570], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0018495593685656786\n",
      "tensor([0.2102, 0.7898], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.044164106249809265\n",
      "tensor([9.9959e-01, 4.0519e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6415499715094484e-07\n",
      "tensor([0.8878, 0.1122], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.012589609250426292\n",
      "tensor([0.0562, 0.9438], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8907253742218018\n",
      "tensor([0.9943, 0.0057], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9886950254440308\n",
      "tensor([0.9303, 0.0697], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0048646386712789536\n",
      "tensor([7.1593e-04, 9.9928e-01], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9985687136650085\n",
      "tensor([0.9984, 0.0016], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5272715902247e-06\n",
      "tensor([9.9963e-01, 3.7146e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.379828518111026e-07\n",
      "tensor([0.5525, 0.4475], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3052063584327698\n",
      "tensor([9.9999e-01, 6.3057e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999873638153076\n",
      "tensor([0.5813, 0.4187], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.33789652585983276\n",
      "tensor([1.0000e+00, 1.1007e-14], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.058136019957113e-29\n",
      "tensor([0.5812, 0.4188], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.33780986070632935\n",
      "tensor([0.4702, 0.5298], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.22106678783893585\n",
      "tensor([0.9892, 0.0108], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0001171361654996872\n",
      "tensor([0.1205, 0.8795], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.014527175575494766\n",
      "tensor([0.4231, 0.5769], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1789928376674652\n",
      "tensor([0.6547, 0.3453], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4286004602909088\n",
      "tensor([0.9873, 0.0127], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00016203871928155422\n",
      "tensor([0.7138, 0.2862], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.08188565820455551\n",
      "tensor([9.9997e-01, 3.4544e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1941991839847788e-09\n",
      "tensor([0.2236, 0.7764], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6027796268463135\n",
      "tensor([9.9996e-01, 3.7931e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.4378975787820991e-09\n",
      "tensor([1.0000e+00, 9.7882e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999997615814209\n",
      "tensor([0.8277, 0.1723], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6850964426994324\n",
      "tensor([0.4221, 0.5779], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1781703233718872\n",
      "tensor([1.0000e+00, 7.8083e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999998211860657\n",
      "tensor([9.9987e-01, 1.3469e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8143769153766698e-08\n",
      "tensor([1.0000e+00, 7.1637e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.5659160799368395e-17\n",
      "tensor([9.9990e-01, 1.0019e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0044918674623204e-08\n",
      "tensor([9.9948e-01, 5.1805e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.6836275424102496e-07\n",
      "tensor([0.7697, 0.2303], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.05302746221423149\n",
      "tensor([0.2864, 0.7136], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08202894777059555\n",
      "tensor([9.9932e-01, 6.7837e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9986438155174255\n",
      "tensor([0.3557, 0.6443], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.4151161015033722\n",
      "tensor([0.9513, 0.0487], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.002370252273976803\n",
      "tensor([0.7635, 0.2365], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5830051898956299\n",
      "tensor([0.8513, 0.1487], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.022115414962172508\n",
      "tensor([0.1904, 0.8096], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.6554226875305176\n",
      "tensor([9.9988e-01, 1.2456e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.551697081936254e-08\n",
      "tensor([9.9908e-01, 9.2274e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.515069112036144e-07\n",
      "tensor([0.8201, 0.1799], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.032351136207580566\n",
      "tensor([1.0000e+00, 4.9344e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.4118516211979468e-11\n",
      "tensor([9.9993e-01, 6.9378e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.813458964747497e-09\n",
      "tensor([0.3024, 0.6976], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.09143418073654175\n",
      "tensor([0.8068, 0.1932], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6508582830429077\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.948105273186229e-05\n",
      "tensor([9.9924e-01, 7.5944e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.767838047177065e-07\n",
      "tensor([9.9981e-01, 1.8611e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.4620470046320406e-08\n",
      "tensor([0.7632, 0.2368], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5824242234230042\n",
      "tensor([0.9766, 0.0234], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9537106156349182\n",
      "tensor([9.9954e-01, 4.6356e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.1485402612597682e-07\n",
      "tensor([1.0000e+00, 3.1644e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1401605571129125e-13\n",
      "tensor([0.3194, 0.6806], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1020045280456543\n",
      "tensor([0.9914, 0.0086], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9829283356666565\n",
      "tensor([0.9977, 0.0023], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.405196134233847e-06\n",
      "tensor([0.8253, 0.1747], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.030529778450727463\n",
      "tensor([0.9136, 0.0864], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8347554206848145\n",
      "tensor([0.8182, 0.1818], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6695164442062378\n",
      "tensor([9.9997e-01, 3.4640e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.201665211780778e-09\n",
      "tensor([9.9989e-01, 1.1094e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997780919075012\n",
      "tensor([0.6043, 0.3957], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.36514735221862793\n",
      "tensor([9.9999e-01, 1.0888e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1811579492260194e-10\n",
      "tensor([0.2680, 0.7320], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.07184168696403503\n",
      "tensor([9.9996e-01, 3.6346e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3214854766019357e-09\n",
      "tensor([0.9844, 0.0156], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0002434207417536527\n",
      "tensor([9.9991e-01, 8.7130e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9998257160186768\n",
      "tensor([9.9943e-01, 5.7394e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.2936779348347045e-07\n",
      "tensor([0.4290, 0.5710], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1840432584285736\n",
      "tensor([0.9540, 0.0460], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9101568460464478\n",
      "tensor([0.9874, 0.0126], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9748672842979431\n",
      "tensor([0.9791, 0.0209], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00043556265882216394\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.4225531685951864e-06\n",
      "tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.4259512681746855e-05\n",
      "tensor([0.5714, 0.4286], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.18370884656906128\n",
      "tensor([0.6459, 0.3541], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.12535274028778076\n",
      "tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.15940701961517334\n",
      "tensor([1.0000e+00, 7.1012e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.626770002902144e-15\n",
      "tensor([0.1739, 0.8261], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.030247114598751068\n",
      "tensor([0.8397, 0.1603], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.02568521350622177\n",
      "tensor([0.0456, 0.9544], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.002078393241390586\n",
      "tensor([0.9913, 0.0087], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9825785160064697\n",
      "tensor([0.9379, 0.0621], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8797209858894348\n",
      "tensor([0.9130, 0.0870], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0075605567544698715\n",
      "tensor([0.6637, 0.3363], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11306475102901459\n",
      "tensor([1.1726e-05, 9.9999e-01], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.3699125167576653e-10\n",
      "tensor([0.9299, 0.0701], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004920163657516241\n",
      "tensor([1.0000e+00, 2.2089e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.004704550087835e-12\n",
      "tensor([0.7469, 0.2531], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.557803750038147\n",
      "tensor([1.0000e+00, 2.6228e-15], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.439451707681134e-30\n",
      "tensor([9.9998e-01, 1.6524e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.737981785738697e-10\n",
      "tensor([0.9908, 0.0092], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9816355109214783\n",
      "tensor([1.0000e+00, 1.8395e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.290557496621327e-12\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9915107488632202\n",
      "tensor([9.9998e-01, 1.7534e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.0725472166537315e-10\n",
      "tensor([0.9797, 0.0203], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9598903656005859\n",
      "tensor([0.9716, 0.0284], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0008041122928261757\n",
      "tensor([0.9971, 0.0029], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9941811561584473\n",
      "tensor([0.1804, 0.8196], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6716874837875366\n",
      "tensor([6.7684e-05, 9.9993e-01], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9998645782470703\n",
      "tensor([0.4579, 0.5421], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.20968294143676758\n",
      "tensor([0.9633, 0.0367], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9278771281242371\n",
      "tensor([9.9998e-01, 1.6360e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999673366546631\n",
      "tensor([0.9848, 0.0152], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00023095984943211079\n",
      "tensor([0.9786, 0.0214], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00045925681479275227\n",
      "tensor([0.0111, 0.9889], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.00012414137017913163\n",
      "tensor([0.5572, 0.4428], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3104221820831299\n",
      "tensor([0.3929, 0.6071], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.15435221791267395\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.5427124253619695e-06\n",
      "tensor([0.6278, 0.3722], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3940897285938263\n",
      "tensor([9.9997e-01, 2.9940e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999401569366455\n",
      "tensor([0.9973, 0.0027], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9946341514587402\n",
      "tensor([0.9914, 0.0086], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.445245864801109e-05\n",
      "tensor([1.0000e+00, 2.0299e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.902427137745517e-14\n",
      "tensor([0.1244, 0.8756], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.015479112043976784\n",
      "tensor([0.9920, 0.0080], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9840535521507263\n",
      "tensor([1.0000e+00, 1.2755e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999997615814209\n",
      "tensor([9.9956e-01, 4.4162e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.9502382997416134e-07\n",
      "tensor([9.9998e-01, 1.9725e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.8799055634974877e-10\n",
      "tensor([1.0000e+00, 9.3049e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999997615814209\n",
      "tensor([9.9990e-01, 9.7657e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.53448786589206e-09\n",
      "tensor([1.0000e+00, 3.6694e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999992847442627\n",
      "tensor([0.3261, 0.6739], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.10633941739797592\n",
      "tensor([0.6807, 0.3193], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4632861912250519\n",
      "tensor([0.6391, 0.3609], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4084138572216034\n",
      "tensor([0.0436, 0.9564], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0019006769871339202\n",
      "tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9923246502876282\n",
      "tensor([1.0000e+00, 9.4586e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1578704913806949e-14\n",
      "tensor([0.5964, 0.4036], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3557380735874176\n",
      "tensor([1.0000e+00, 4.6345e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.1546753964374332e-11\n",
      "tensor([1.0000e+00, 1.4868e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1053304332816401e-18\n",
      "tensor([9.9998e-01, 2.0335e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.1452249965878707e-10\n",
      "tensor([0.9974, 0.0026], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.63093123876024e-06\n",
      "tensor([0.2491, 0.7509], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5638709664344788\n",
      "tensor([1.0000e+00, 2.0444e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.089721684334046e-18\n",
      "tensor([0.9083, 0.0917], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.008412031456828117\n",
      "tensor([0.8956, 0.1044], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.010903706774115562\n",
      "tensor([0.6359, 0.3641], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.40441596508026123\n",
      "tensor([0.9103, 0.0897], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.008044503629207611\n",
      "tensor([9.9914e-01, 8.6376e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9982732534408569\n",
      "tensor([0.9936, 0.0064], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.155695569352247e-05\n",
      "tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3636484254675452e-05\n",
      "tensor([0.9972, 0.0028], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9944489598274231\n",
      "tensor([0.7991, 0.2009], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6386204957962036\n",
      "tensor([9.9997e-01, 2.6062e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.803935193033794e-10\n",
      "tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9900190830230713\n",
      "tensor([1.0000e+00, 8.8564e-11], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.921826458414427e-21\n",
      "tensor([0.4826, 0.5174], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.23286546766757965\n",
      "tensor([0.8844, 0.1156], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01335718110203743\n",
      "tensor([0.9966, 0.0034], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1336132047290448e-05\n",
      "tensor([9.9927e-01, 7.2507e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.257398356661724e-07\n",
      "tensor([0.8086, 0.1914], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.03662519529461861\n",
      "tensor([0.6806, 0.3194], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.46324238181114197\n",
      "tensor([0.9973, 0.0027], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9945411682128906\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8260078604726004e-06\n",
      "tensor([0.5194, 0.4806], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2697320878505707\n",
      "tensor([0.9595, 0.0405], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0016427154187113047\n",
      "tensor([0.7297, 0.2703], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.07306685298681259\n",
      "tensor([0.8593, 0.1407], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7384118437767029\n",
      "tensor([0.9973, 0.0027], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.393817213596776e-06\n",
      "tensor([1.0000e+00, 2.3447e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.748850348038167e-16\n",
      "tensor([0.8695, 0.1305], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01701856590807438\n",
      "tensor([0.9145, 0.0855], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0073181637562811375\n",
      "tensor([0.6178, 0.3822], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.38163143396377563\n",
      "tensor([0.8255, 0.1745], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.03045150265097618\n",
      "tensor([0.6740, 0.3260], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.10625983774662018\n",
      "tensor([0.5597, 0.4403], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.19382165372371674\n",
      "tensor([0.9785, 0.0215], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0004643742286134511\n",
      "tensor([0.9763, 0.0237], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9532185196876526\n",
      "tensor([0.7896, 0.2104], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.044251326471567154\n",
      "tensor([0.9531, 0.0469], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9083490967750549\n",
      "tensor([0.2572, 0.7428], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5516816973686218\n",
      "tensor([0.9604, 0.0396], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9223296642303467\n",
      "tensor([0.9395, 0.0605], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.003657848574221134\n",
      "tensor([0.0157, 0.9843], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.00024792487965896726\n",
      "tensor([0.9980, 0.0020], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.115851879760157e-06\n",
      "tensor([9.9973e-01, 2.7159e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.3768077868408e-08\n",
      "tensor([1.0000e+00, 2.5127e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.1569474223129716e-18\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.918572343129199e-05\n",
      "tensor([1.0000e+00, 4.0130e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6266007638043867e-11\n",
      "tensor([0.7456, 0.2544], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.06472184509038925\n",
      "tensor([0.6959, 0.3041], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4842694401741028\n",
      "tensor([0.3564, 0.6436], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.41426974534988403\n",
      "tensor([9.9998e-01, 1.6603e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.7510765887583943e-10\n",
      "tensor([0.4724, 0.5276], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.22313180565834045\n",
      "tensor([0.9023, 0.0977], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00953824445605278\n",
      "tensor([9.9994e-01, 6.2089e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9998757839202881\n",
      "tensor([0.9753, 0.0247], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9511370658874512\n",
      "tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3501321013318375e-05\n",
      "tensor([9.9999e-01, 5.8143e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.396291581303501e-11\n",
      "tensor([0.8295, 0.1705], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6880912780761719\n",
      "tensor([0.4710, 0.5290], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.22184841334819794\n",
      "tensor([0.5549, 0.4451], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.30795586109161377\n",
      "tensor([0.4641, 0.5359], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.2872389554977417\n",
      "tensor([0.0352, 0.9648], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0012363515561446548\n",
      "tensor([1.0000e+00, 1.0504e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1272139905510459e-12\n",
      "tensor([0.2912, 0.7088], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.08480208367109299\n",
      "tensor([1.0000e+00, 7.2732e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999985694885254\n",
      "tensor([0.6164, 0.3836], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.37998560070991516\n",
      "tensor([1.0000e+00, 1.0891e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1686407050404135e-12\n",
      "tensor([0.9581, 0.0419], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0017517360392957926\n",
      "tensor([0.5371, 0.4629], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.28843265771865845\n",
      "tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.526196840335615e-05\n",
      "tensor([0.9268, 0.0732], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8590071201324463\n",
      "tensor([0.9813, 0.0187], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0003503894549794495\n",
      "tensor([9.9986e-01, 1.3721e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8826803227511846e-08\n",
      "tensor([0.9860, 0.0140], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00019563574460335076\n",
      "tensor([1.0000e+00, 5.0582e-11], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2792528916943177e-21\n",
      "tensor([0.9783, 0.0217], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0004705000319518149\n",
      "tensor([0.9803, 0.0197], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00038855240563862026\n",
      "tensor([9.9999e-01, 1.3901e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.938906812881669e-10\n",
      "tensor([9.9994e-01, 6.2361e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.888005029040187e-09\n",
      "tensor([9.9998e-01, 2.3470e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.511643363931285e-10\n",
      "tensor([0.9605, 0.0395], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.922468900680542\n",
      "tensor([0.8280, 0.1720], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6855770349502563\n",
      "tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2346141375019215e-05\n",
      "tensor([0.8811, 0.1189], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01413486897945404\n",
      "tensor([0.8614, 0.1386], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.019201841205358505\n",
      "tensor([1.0000e+00, 1.2639e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.987222907587533e-19\n",
      "tensor([1.0000e+00, 4.9100e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2053960700951234e-15\n",
      "tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8323165774345398\n",
      "tensor([0.7422, 0.2578], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.06646765768527985\n",
      "tensor([0.9198, 0.0802], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.006431426387280226\n",
      "tensor([9.9957e-01, 4.3069e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.8547206082075718e-07\n",
      "tensor([0.9900, 0.0100], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00010035408195108175\n",
      "tensor([9.9967e-01, 3.2974e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0872758338109634e-07\n",
      "tensor([0.0087, 0.9913], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "7.57055968279019e-05\n",
      "tensor([0.9382, 0.0618], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00381901441141963\n",
      "tensor([0.9970, 0.0030], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.890458957466763e-06\n",
      "tensor([0.9901, 0.0099], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.874587703961879e-05\n",
      "tensor([0.0060, 0.9940], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9879715442657471\n",
      "tensor([0.0040, 0.9960], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9920253157615662\n",
      "tensor([0.9572, 0.0428], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0018346451688557863\n",
      "tensor([0.6575, 0.3425], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.432283878326416\n",
      "tensor([0.1002, 0.8998], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.8096898198127747\n",
      "tensor([0.9947, 0.0053], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.7966845664195716e-05\n",
      "tensor([0.5603, 0.4397], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.31392449140548706\n",
      "tensor([0.9814, 0.0186], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9631736874580383\n",
      "tensor([0.6659, 0.3341], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11160717904567719\n",
      "tensor([9.9990e-01, 1.0415e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.085122924848747e-08\n",
      "tensor([0.9988, 0.0012], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3875510376237798e-06\n",
      "tensor([0.5714, 0.4286], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3264657258987427\n",
      "tensor([0.9876, 0.0124], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9752733707427979\n",
      "tensor([0.4062, 0.5938], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.1649894416332245\n",
      "tensor([0.8743, 0.1257], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.764388918876648\n",
      "tensor([9.9993e-01, 7.2477e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.253055768150716e-09\n",
      "tensor([9.9952e-01, 4.8449e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9990313053131104\n",
      "tensor([9.9919e-01, 8.0833e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9983839988708496\n",
      "tensor([0.8712, 0.1288], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7590340375900269\n",
      "tensor([0.9985, 0.0015], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9969794154167175\n",
      "tensor([0.9880, 0.0120], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00014400886720977724\n",
      "tensor([1.0000e+00, 1.0179e-10], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.180277958940506e-21\n",
      "tensor([0.9123, 0.0877], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.832207441329956\n",
      "tensor([0.8263, 0.1737], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.03018765337765217\n",
      "tensor([0.6983, 0.3017], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.09101241081953049\n",
      "tensor([0.9986, 0.0014], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.9033344642593875e-06\n",
      "tensor([9.9988e-01, 1.1916e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.420532846907463e-08\n",
      "tensor([0.9892, 0.0108], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00011677832662826404\n",
      "tensor([9.9906e-01, 9.4071e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9981194734573364\n",
      "tensor([9.9995e-01, 5.3453e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.854725789092072e-09\n",
      "tensor([0.6647, 0.3353], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11241047084331512\n",
      "tensor([0.8894, 0.1106], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.012236909940838814\n",
      "tensor([9.9991e-01, 8.7979e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999824047088623\n",
      "tensor([0.9545, 0.0455], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0020737890154123306\n",
      "tensor([9.9975e-01, 2.5393e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.44909690095119e-08\n",
      "tensor([0.5096, 0.4904], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2596726715564728\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.3127112197253155e-06\n",
      "tensor([1.0000e+00, 2.9364e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.153528664609679e-14\n",
      "tensor([9.9996e-01, 4.3929e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999120831489563\n",
      "tensor([1.0000e+00, 1.7636e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.555191798781604e-16\n",
      "tensor([0.4070, 0.5930], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.16568158566951752\n",
      "tensor([0.2809, 0.7191], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.07888136804103851\n",
      "tensor([0.1864, 0.8136], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.034761492162942886\n",
      "tensor([0.9790, 0.0210], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0004392710397951305\n",
      "tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9881086945533752\n",
      "tensor([9.9993e-01, 6.7195e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.517783924740115e-09\n",
      "tensor([1.0000e+00, 5.9417e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.541561033153229e-13\n",
      "tensor([9.9921e-01, 7.9372e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9984133243560791\n",
      "tensor([9.9999e-01, 7.4915e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.626245996870338e-11\n",
      "tensor([0.0183, 0.9817], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.0003358784597367048\n",
      "tensor([0.2631, 0.7369], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.06922093033790588\n",
      "tensor([0.3699, 0.6301], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3970149755477905\n",
      "tensor([9.9965e-01, 3.5346e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2493234180510626e-07\n",
      "tensor([1.0000e+00, 2.1400e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999957084655762\n",
      "tensor([0.0058, 0.9942], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "3.364326403243467e-05\n",
      "tensor([9.9976e-01, 2.4062e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.7899967487173853e-08\n",
      "tensor([0.9984, 0.0016], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.4525963908672566e-06\n",
      "tensor([9.9968e-01, 3.2144e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.0330622046694771e-07\n",
      "tensor([9.9954e-01, 4.5731e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.091226463107887e-07\n",
      "tensor([0.0108, 0.9892], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9784734845161438\n",
      "tensor([0.5978, 0.4022], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3574053645133972\n",
      "tensor([0.0014, 0.9986], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.8414657461107709e-06\n",
      "tensor([0.8954, 0.1046], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.010936001315712929\n",
      "tensor([9.9993e-01, 6.6578e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999866783618927\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.2040911769872764e-06\n",
      "tensor([0.9408, 0.0592], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.003501198021695018\n",
      "tensor([0.9238, 0.0762], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.005807858891785145\n",
      "tensor([1.0000e+00, 3.3385e-08], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999999403953552\n",
      "tensor([0.2550, 0.7450], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.5549757480621338\n",
      "tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.915399454650469e-05\n",
      "tensor([0.9413, 0.0587], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.003447561524808407\n",
      "tensor([0.9880, 0.0120], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0001448530238121748\n",
      "tensor([1.0000e+00, 8.7959e-09], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.868417998956111e-17\n",
      "tensor([0.6744, 0.3256], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.4547988772392273\n",
      "tensor([0.9828, 0.0172], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00029496930073946714\n",
      "tensor([0.9966, 0.0034], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9932790398597717\n",
      "tensor([0.9912, 0.0088], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9823839068412781\n",
      "tensor([1.0000e+00, 4.6989e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.184727919407603e-11\n",
      "tensor([0.9663, 0.0337], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0011333721922710538\n",
      "tensor([9.9997e-01, 3.1307e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "9.815320778372438e-10\n",
      "tensor([0.8122, 0.1878], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.03525358438491821\n",
      "tensor([1.0000e+00, 1.3502e-09], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "1.0\n",
      "tensor([0.9707, 0.0293], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9421859383583069\n",
      "tensor([0.6007, 0.3993], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.15943695604801178\n",
      "tensor([0.9100, 0.0900], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.8281344175338745\n",
      "tensor([0.4651, 0.5349], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.2860662043094635\n",
      "tensor([0.8421, 0.1579], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.024945266544818878\n",
      "tensor([1.0000e+00, 5.7209e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.6364127028328551e-15\n",
      "tensor([0.5506, 0.4494], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.30313482880592346\n",
      "tensor([9.9992e-01, 7.7190e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.962782267943112e-09\n",
      "tensor([0.7356, 0.2644], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5411794185638428\n",
      "tensor([0.9868, 0.0132], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9738289713859558\n",
      "tensor([0.3481, 0.6519], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.12118326127529144\n",
      "tensor([1.0000e+00, 2.7251e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.4719492745845e-12\n",
      "tensor([1.0000e+00, 1.8561e-08], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.722603096246088e-16\n",
      "tensor([0.9022, 0.0978], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00956774316728115\n",
      "tensor([0.1513, 0.8487], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.022881940007209778\n",
      "tensor([0.5982, 0.4018], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.35784563422203064\n",
      "tensor([0.3585, 0.6415], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.12850700318813324\n",
      "tensor([0.7300, 0.2700], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.07288853824138641\n",
      "tensor([0.9887, 0.0113], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00012838955444749445\n",
      "tensor([0.5131, 0.4869], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.263317734003067\n",
      "tensor([0.9982, 0.0018], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9964484572410583\n",
      "tensor([0.9614, 0.0386], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0014919093810021877\n",
      "tensor([9.9997e-01, 2.7851e-05], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.999944269657135\n",
      "tensor([0.9676, 0.0324], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0010480191558599472\n",
      "tensor([0.5476, 0.4524], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.29984214901924133\n",
      "tensor([0.9003, 0.0997], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.009945358149707317\n",
      "tensor([0.8550, 0.1450], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.02101258933544159\n",
      "tensor([0.9538, 0.0462], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9097399711608887\n",
      "tensor([0.8876, 0.1124], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.012636801227927208\n",
      "tensor([0.9821, 0.0179], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9645013809204102\n",
      "tensor([0.0308, 0.9692], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.9393032193183899\n",
      "tensor([0.8925, 0.1075], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.01154756173491478\n",
      "tensor([1.0000e+00, 5.7819e-07], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.4478575051434535e-13\n",
      "tensor([0.6548, 0.3452], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.11918053030967712\n",
      "tensor([9.9980e-01, 1.9597e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "3.839400264382675e-08\n",
      "tensor([9.9919e-01, 8.0540e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.487015298262122e-07\n",
      "tensor([9.9989e-01, 1.0974e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9997804760932922\n",
      "tensor([0.9915, 0.0085], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.187302253441885e-05\n",
      "tensor([0.9689, 0.0311], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0009674621978774667\n",
      "tensor([0.9984, 0.0016], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.6542097657511476e-06\n",
      "tensor([0.8563, 0.1437], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.020642193034291267\n",
      "tensor([0.9967, 0.0033], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1076674127252772e-05\n",
      "tensor([0.9897, 0.0103], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00010554309119470417\n",
      "tensor([1.0000e+00, 1.1457e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.366885337555912e-12\n",
      "tensor([0.6765, 0.3235], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.45770978927612305\n",
      "tensor([9.9905e-01, 9.4658e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "8.960158766058157e-07\n",
      "tensor([0.9989, 0.0011], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1348729458404705e-06\n",
      "tensor([0.8260, 0.1740], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.6822202205657959\n",
      "tensor([0.0559, 0.9441], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.003123339032754302\n",
      "tensor([0.9979, 0.0021], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.512304258241784e-06\n",
      "tensor([0.9978, 0.0022], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.655455086322036e-06\n",
      "tensor([0.5689, 0.4311], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3236894905567169\n",
      "tensor([0.6794, 0.3206], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.10279526561498642\n",
      "tensor([0.9725, 0.0275], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0007558982470072806\n",
      "tensor([9.9999e-01, 5.3960e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999892115592957\n",
      "tensor([0.2319, 0.7681], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.05376891791820526\n",
      "tensor([1.0000e+00, 1.5302e-07], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999997019767761\n",
      "tensor([0.9366, 0.0634], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.004018144682049751\n",
      "tensor([9.9987e-01, 1.3122e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.7222776094172332e-08\n",
      "tensor([0.8461, 0.1539], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.7158709168434143\n",
      "tensor([1.0000e+00, 1.0406e-06], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "1.1169628590101954e-12\n",
      "tensor([0.1690, 0.8310], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.028573039919137955\n",
      "tensor([9.9921e-01, 7.8896e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.2252763655124e-07\n",
      "tensor([9.9936e-01, 6.4182e-04], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9987168312072754\n",
      "tensor([0.5239, 0.4761], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.2745009660720825\n",
      "tensor([0.7601, 0.2399], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.5777149796485901\n",
      "tensor([0.9936, 0.0064], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "4.0945033106254414e-05\n",
      "tensor([0.9822, 0.0178], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.00031635910272598267\n",
      "tensor([0.9713, 0.0287], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0008209480438381433\n",
      "tensor([2.5388e-08, 1.0000e+00], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "3.2226564912327853e-16\n",
      "tensor([0.9786, 0.0214], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.0004560467496048659\n",
      "tensor([0.5554, 0.4446], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.3084983825683594\n",
      "tensor([0.9772, 0.0228], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.000517798587679863\n",
      "tensor([9.9976e-01, 2.4264e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "5.887646992164264e-08\n",
      "tensor([0.4503, 0.5497], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.20280849933624268\n",
      "tensor([0.8528, 0.1472], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.727241039276123\n",
      "tensor([0.3952, 0.6048], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "0.3657281994819641\n",
      "tensor([1.0000e+00, 3.7315e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999925494194031\n",
      "tensor([0.9976, 0.0024], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9952602386474609\n",
      "tensor([9.9999e-01, 7.4372e-06], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.9999851584434509\n",
      "tensor([0.9947, 0.0053], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "2.775257598841563e-05\n",
      "tensor([9.9922e-01, 7.7893e-04], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "6.067210165383585e-07\n",
      "tensor([0.1144, 0.8856], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n",
      "0.013077840209007263\n",
      "tensor([9.9997e-01, 2.7449e-05], grad_fn=<SoftmaxBackward>) tensor([1., 0.])\n",
      "7.52600592957009e-10\n",
      "tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward>) tensor([0., 1.])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1e9e58c591b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-3d93086541cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, epochs, lr, weight_decay)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.9.0/install/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/pkg.7/pytorch/1.9.0/install/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da28243",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "edge_index.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db70dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_features(), dataset.num_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e84fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52146b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
